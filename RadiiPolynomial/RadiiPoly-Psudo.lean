/-
Lean 4.24.0-rc1 (arm64-apple-darwin), Mathlib4 (commit near 919e2972â€¦)
Tip: run `lake exe cache get` once to prefetch Mathlib artifacts.
-/

import Mathlib.Analysis.SpecificLimits.Basic
import Mathlib.Data.Setoid.Basic
import Mathlib.Dynamics.FixedPoints.Topology
import Mathlib.Topology.MetricSpace.Lipschitz
import Mathlib.Analysis.Calculus.Deriv.AffineMap
import Mathlib.Analysis.Calculus.Deriv.Comp
import Mathlib.Analysis.Calculus.Deriv.Mul
import Mathlib.Analysis.Calculus.Deriv.Slope
import Mathlib.Analysis.Normed.Group.AddTorsor
import Mathlib.Analysis.Normed.Module.Convex
import Mathlib.Analysis.RCLike.Basic
import Mathlib.Topology.Instances.RealVectorSpace
import Mathlib.Topology.LocallyConstant.Basic
import Mathlib.Analysis.Normed.Group.InfiniteSum
import Mathlib.Algebra.BigOperators.Group.Finset.Basic
import Mathlib.Analysis.Normed.Operator.ContinuousLinearMap
import Mathlib.Algebra.Module.LinearMap.Defs


open scoped Topology BigOperators
open Metric Set Filter ContinuousLinearMap



/-
NormedAddCommGroup: A *normed* group is an additive group endowed with a norm for which `dist x y = â€–x - yâ€–` defines a *metric space structure*.

NormedSpace â„ E: A normed space over the reals is a *vector space over the real numbers* equipped with a norm that satisfies the properties of a norm (non-negativity, definiteness, homogeneity, and triangle inequality).

CompleteSpace E: A *complete* space is a metric space in which every Cauchy sequence converges to a limit within the space.

â‡’ E is a Banach space over â„.
-/
variable {E : Type*} [NormedAddCommGroup E] [NormedSpace â„ E] [CompleteSpace E]

abbrev I := ContinuousLinearMap.id â„ E

/--
Newton-like map `T x = x - A (f x)` on a Banach space.
From equation (2.7) in the informal proof.
- `f` is the nonlinear map whose zeros we seek
- `A` is a linear operator (approximate inverse of Df at some point)
-/
def NewtonLikeMap (f : E â†’ E) (A : E â†’L[â„] E) (x : E) : E := x - A (f x)

/--
`closedBall x Îµ` is the set of all points `y` with `dist y x â‰¤ Îµ`.
This defines the domain where we'll prove T is a contraction.
-/
def WorkingDomain (xBar : E) (r : â„) : Set E := closedBall xBar r



section Proposition_2_3_1
/-
================================================================================
PROPOSITION 2.3.1: Equivalence between fixed points of T and zeros of f
================================================================================

From the informal proof (page 19):
"Let X and Y be vector spaces. Let U âŠ‚ X and consider f : U â†’ Y.
Assume that A: Y â†’ X is an injective linear map. Let T : U â†’ X be defined by
T(x) = x - Af(x). Then, T(xÌƒ) = xÌƒ if and only if f(xÌƒ) = 0."
-/

-- Omit `[CompleteSpace]` for this section
variable {E : Type*} [NormedAddCommGroup E] [NormedSpace â„ E]
/--
T(x) = x - A(f(x)) = 0 â†” f(x) = 0 when A is injective.
-/
lemma fixedPoint_injective_iff_zero
  {f : E â†’ E} {A : E â†’L[â„] E}
  (hA : Function.Injective A) (x : E) :
  NewtonLikeMap f A x = x â†” f x = 0 := by
  -- Unfold the definition of NewtonLikeMap: T(x) = x - A(f(x))
  unfold NewtonLikeMap

  -- T(x) = x means x - A(f(x)) = x
  -- This is equivalent to A(f(x)) = 0
  calc
    x - A (f x) = x â†” A (f x) = 0 := by
      constructor
      Â· intro h
        -- From x - A(f(x)) = x, subtract x from both sides
        have h_sub : x - (x - A (f x)) = x - x := by rw [h]
        calc
          A (f x)
            = x - (x - A (f x)) := by abel
          _ = x - x             := by rw [h_sub]
          _ = 0                 := by rw [sub_self x]
        -- linarith [h]
      Â· intro h
        -- From A(f(x)) = 0, we get x - 0 = x
        simp [h]
    _ â†” f x = 0 := by
      -- Since A is injective, A(y) = 0 implies y = 0
      constructor
      Â· intro h
        -- A is a linear map, so A(0) = 0
        haveI : A 0 = 0 := map_zero A

        -- (1) We haveI `h : A (f x) = 0`. We want to show `A (f x) = A 0`.
        -- To do this, we first flip the equality `A 0 = 0` to `0 = A 0`.
        haveI : 0 = A 0 := this.symm

        -- (2) Now we chain the two equalities together.
        -- `h` gives us `A (f x) = 0`
        -- `this` gives us `0 = A 0`
        -- By transitivity of equality, we get `A (f x) = A 0`.
        haveI : A (f x) = A 0 := h.trans this

        -- (3) Apply the injectivity of A.
        -- `hA` is the hypothesis `Function.Injective A`.
        -- By definition, this means if `A y = A z`, then `y = z`.
        -- We apply `hA` to our proof `h_eq_A_zero` to conclude `f x = 0`.
        exact hA this

      Â· intro h
        -- If f(x) = 0, then A(f(x)) = A(0) = 0
        simp [h]

end Proposition_2_3_1



/-
==============================================================================
NEUMANN SERIES THEOREM FOR INVERTIBILITY
==============================================================================

This section proves that operators close to the identity are invertible,
with the inverse given by the Neumann series.

We break the proof into manageable lemmas, each handling one aspect.

Note: We assume `[Nontrivial E]` throughout this section since we're working
with operators on meaningful Banach spaces where Newton's method makes sense.
In practice, spaces like â„â¿ (n â‰¥ 1), function spaces, etc. are all nontrivial.
-/
section NeumannSeries

variable {E : Type*} [NormedAddCommGroup E] [NormedSpace â„ E] [CompleteSpace E] [Nontrivial E]



omit [CompleteSpace E] in
/--
First lemma: nth powers norm submultiplicativity
of the operator norm.
-/
lemma norm_pow_le_pow_norm (X : E â†’L[â„] E) (n : â„•) :
  â€–X ^ nâ€– â‰¤ â€–Xâ€– ^ n := by
  induction n with
  | zero =>
    -- Base case: â€–X^0â€– = â€–Iâ€– = 1 = â€–Xâ€–^0
    calc
      â€–X ^ 0â€–
        -- Can I do rw here instead of simp???????
        = â€–ContinuousLinearMap.id â„ Eâ€– := by simp [pow_zero]
      -- Since E is nontrivial, we have â€–Iâ€– = 1
      _ = 1                            := by rw [ContinuousLinearMap.norm_id]
      _ = â€–Xâ€– ^ 0                      := by rw [pow_zero]
      _ â‰¤ â€–Xâ€– ^ 0                      := by exact le_rfl

  | succ m _ =>
    -- Inductive step: use submultiplicativity â€–A Bâ€– â‰¤ â€–Aâ€– â€–Bâ€–
    calc â€–X ^ (m + 1)â€– = â€–X ^ m * Xâ€– := by rw [pow_succ]
      _ â‰¤ â€–X ^ mâ€– * â€–Xâ€– := by
        -- ContinuousLinearMap forms a normed algebra where norm is submultiplicative
        -- The standard lemma for this is norm_mul_le
        exact norm_mul_le (X ^ m) X
      _ â‰¤ â€–Xâ€– ^ m * â€–Xâ€– := by
        gcongr
      _ = â€–Xâ€– ^ (m + 1) := by
        rw [pow_succ]



omit [CompleteSpace E] in
/--
Second lemma: If â€–Xâ€– < 1, then the series âˆ‘ â€–X^nâ€– is summable.
This follows by comparison with the geometric series âˆ‘ â€–Xâ€–^n.
-/
lemma norm_series_summable_of_norm_lt_one {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) :
  Summable (fun n : â„• => â€–X ^ nâ€–) := by
  -- First, get the geometric series to converge
  -- Since â€–Xâ€– is a nonnegative real, we can use it directly
  haveI h_geometric : Summable (fun n : â„• => (â€–Xâ€– : â„) ^ n) := by
    -- Apply the geometric series test
    rw [summable_geometric_iff_norm_lt_one]
    -- â€–Xâ€– is already nonnegative, so â€–â€–Xâ€–â€– = â€–Xâ€–
    simp only [norm_norm]
    exact h
    -- simpa
    -- simpa using h
  -- Now use comparison: â€–X^nâ€– â‰¤ â€–Xâ€–^n
  refine Summable.of_nonneg_of_le ?_ (norm_pow_le_pow_norm X) h_geometric
  -- Show each term is nonnegative (norms are always nonnegative)
  intro n
  exact norm_nonneg _



/--
Third lemma: If â€–Xâ€– < 1, then the operator series âˆ‘ X^n is summable
in the Banach space of continuous linear maps.
This uses the completeness of the space.
-/
lemma operator_series_summable_of_norm_lt_one {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) :
  Summable (fun n : â„• => X ^ n) := by
  -- In a Banach space, absolute convergence implies convergence
  -- `Summable.of_norm` turns goal from `Summable (X^n)` to `Summable (â€–X^nâ€–)`.
  apply Summable.of_norm
  exact norm_series_summable_of_norm_lt_one h



/--
Helper definition: The Neumann series sum S = âˆ‘ X^n exists when â€–Xâ€– < 1.
This sum will be shown to be the inverse of (I - X).
-/
noncomputable def neumannSeriesSum {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) : E â†’L[â„] E :=
  haveI : Summable (fun n : â„• => X ^ n) :=
    operator_series_summable_of_norm_lt_one h
  -- `âˆ‘' i, f i` is the sum of f if it exists and is unconditionally convergent, or 0 otherwise.
  âˆ‘' n : â„•, X ^ n



omit [CompleteSpace E] [Nontrivial E] in
/--
Finite telescoping: (I - X) âˆ˜ (âˆ‘_{n=0}^{N-1} X^n) = I - X^N
-/
lemma finite_telescoping {X : E â†’L[â„] E} (N : â„•) :
  (I - X).comp (âˆ‘ n âˆˆ Finset.range N, X ^ n) =
   I - X ^ N := by
  -- Prove equality of linear maps by showing they agree on all inputs
  ext x
  simp

  calc
    -- WTS: ((I - X) âˆ˜ S) x = (I - X) (S x)
    -- where S = âˆ‘_{n=0}^{N-1} X^n.
    -- Distribute X over the sum using linearity: X(âˆ‘X^n x) = ( âˆ‘X^{n+1} x )
    âˆ‘ n âˆˆ Finset.range N, (X ^ n) x - âˆ‘ x_1 âˆˆ Finset.range N, X ((X ^ x_1) x) =
    (âˆ‘ n âˆˆ Finset.range N, X ^ n) x - (âˆ‘ n âˆˆ Finset.range N, X ^ (n + 1)) x := by
        -- The first term is unchanged, removed from the goal by `congr 1` (`rfl`)
        congr 1
        -- Move X inside the sum
        simp only [coe_sum', Finset.sum_apply]
        -- Rewrite X âˆ˜ (X^n) as X^{n+1}
        haveI {n : â„•} {x : E}: X ((X ^ n) x) = (X ^ (n + 1)) x := by
          rw [pow_succ', â† comp_apply]
          rfl
        simp [this]

    -- The telescoping: âˆ‘_{n=0}^{N-1} X^n x - âˆ‘_{n=0}^{N-1} X^{n+1} x = x - X^N x
    _ = x - (X ^ N) x := by
        have telescope : âˆ€ M : â„•,
          âˆ‘ n âˆˆ Finset.range M, (X ^ n) x - âˆ‘ n âˆˆ Finset.range M, (X ^ (n + 1)) x =
          (X ^ 0) x - (X ^ M) x := by
          intro M
          induction M with
          | zero      => simp
          | succ k ih =>
            -- break down a sum over k+1 terms into
            -- a sum over k terms plus the final term
            rw [Finset.sum_range_succ, Finset.sum_range_succ]
            simp only [pow_zero, one_apply]
            calc
              (âˆ‘ n âˆˆ Finset.range k, (X ^ n) x) + (X ^ k) x -
              ((âˆ‘ n âˆˆ Finset.range k, (X ^ (n + 1)) x) +
              (X ^ (k + 1)) x)
              = (âˆ‘ n âˆˆ Finset.range k, (X ^ n) x) -
                (âˆ‘ n âˆˆ Finset.range k, (X ^ (n + 1)) x) +
                ((X ^ k) x - (X ^ (k + 1)) x)
              := by abel
              _ = ((X ^ 0) x - (X ^ k) x) + ((X ^ k) x - (X ^ (k + 1)) x)
                := by rw [ih]
              _ = (X ^ 0) x - (X ^ (k + 1)) x
                := by abel

        simp [telescope N]



section FiniteTelescopingLegacy
/-
Finite telescoping - legacy version with redundant steps.
-/
-- lemma finite_telescoping_legacy {X : E â†’L[â„] E} (N : â„•) :
--   (I - X).comp (âˆ‘ n âˆˆ Finset.range N, X ^ n) =
--    I - X ^ N := by
--   -- Prove equality of linear maps by showing they agree on all inputs
--   ext x

--   simp
--   -- -- Simplify the goal to x - X^N x
--   -- haveI : (I - X ^ N) x = x - (X ^ N) x := by
--   --   calc
--   --     (I - X ^ N) x
--   --       = (I) x - (X ^ N) x
--   --       := by rw [sub_apply]
--   --     _ = x - (X ^ N) x := by rw [id_apply]
--   -- rw [this]

--   calc
--     -- Goal: ((I - X) âˆ˜ S) x = (I - X) (S x)
--     -- where S = âˆ‘_{n=0}^{N-1} X^n.
--     -- ((I - X).comp (âˆ‘ n âˆˆ Finset.range N, X ^ n)) x
--     --   = (I - X) ((âˆ‘ n âˆˆ Finset.range N, X ^ n) x)
--     --   := by rw [ContinuousLinearMap.coe_comp', Function.comp_apply]

--     -- Apply the subtraction operator: (I - X)(S x) = (S x) - X(S x)
--     -- _ = (âˆ‘ n âˆˆ Finset.range N, X ^ n) x - X ((âˆ‘ n âˆˆ Finset.range N, X ^ n) x)
--     --   := by rw [sub_apply, id_apply]

--     -- Distribute X over the sum using linearity: X(âˆ‘X^n x) = ( âˆ‘X^{n+1} x )
--     âˆ‘ n âˆˆ Finset.range N, (X ^ n) x - âˆ‘ x_1 âˆˆ Finset.range N, X ((X ^ x_1) x) = (âˆ‘ n âˆˆ Finset.range N, X ^ n) x - (âˆ‘ n âˆˆ Finset.range N, X ^ (n + 1)) x
--       := by
--         -- The first term is unchanged, removed from the goal by `congr 1` (`rfl`)
--         congr 1
--         -- Move X inside the sum
--         simp [sum_apply]
--         -- Simplify the goal again by dropping the sum
--         -- congr
--         -- change summation index to n
--         -- ext n
--         -- Rewrite X âˆ˜ (X^n) as X^{n+1}
--         haveI {n : â„•} {x : E}: X ((X ^ n) x) = (X ^ (n + 1)) x := by
--           rw [pow_succ', â† comp_apply]
--           rfl
--         simp [this]

--     -- The telescoping: âˆ‘_{n=0}^{N-1} X^n x - âˆ‘_{n=0}^{N-1} X^{n+1} x = x - X^N x
--     _ = x - (X ^ N) x := by
--         have telescope : âˆ€ M : â„•,
--           âˆ‘ n âˆˆ Finset.range M, (X ^ n) x - âˆ‘ n âˆˆ Finset.range M, (X ^ (n + 1)) x =
--           (X ^ 0) x - (X ^ M) x := by
--           intro M
--           induction M with
--           | zero => simp
--           | succ k ih =>
--             -- break down a sum over k+1 terms into
--             -- a sum over k terms plus the final term
--             rw [Finset.sum_range_succ, Finset.sum_range_succ]
--             simp
--             calc
--               (âˆ‘ n âˆˆ Finset.range k, (X ^ n) x) + (X ^ k) x -
--               ((âˆ‘ n âˆˆ Finset.range k, (X ^ (n + 1)) x) +
--               (X ^ (k + 1)) x)
--               = (âˆ‘ n âˆˆ Finset.range k, (X ^ n) x) -
--                 (âˆ‘ n âˆˆ Finset.range k, (X ^ (n + 1)) x) +
--                 ((X ^ k) x - (X ^ (k + 1)) x)
--               := by abel
--               _ = ((X ^ 0) x - (X ^ k) x) + ((X ^ k) x - (X ^ (k + 1)) x)
--                 := by rw [ih]
--               _ = (X ^ 0) x - (X ^ (k + 1)) x
--                 := by abel

--         simp [telescope N]
end FiniteTelescopingLegacy



-- Partial sum convergence: âˆ€ Îµ > 0, âˆƒ N, âˆ€ n â‰¥ N: â€–S_n - Sâ€– < Îµ
lemma h_partial {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) : âˆ€ Îµ > 0, âˆƒ N, âˆ€ n â‰¥ N,
  â€–(âˆ‘ k âˆˆ Finset.range n, X ^ k) - âˆ‘' k, X ^ kâ€– < Îµ := by
  intro Îµ hÎµ
  have h_summable := operator_series_summable_of_norm_lt_one h
  -- `HasSum.tendsto_sum_nat` :
  -- (fun n => âˆ‘ i in Finset.range n, f i) tends to a as n â†’ âˆ
  have := h_summable.hasSum.tendsto_sum_nat
  -- `Metric.tendsto_atTop` :
  -- expands the definition of `tendsto` using Îµ/Î´ language w/ a distance function
  rw [Metric.tendsto_atTop] at this
  exact this Îµ hÎµ

-- Power vanishing: â€–Xâ€– < 1 âŸ¹ â€–X^nâ€– â‰¤ â€–Xâ€–^n â†’ 0
omit [CompleteSpace E] in
lemma h_zero_lim {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) : âˆ€ Îµ > 0, âˆƒ N, âˆ€ n â‰¥ N, â€–X ^ nâ€– < Îµ := by
  intro Îµ hÎµ
  -- `atTop` is the filter representing the limit `â†’ âˆ` on an ordered set
  -- `Tendsto` : {Î± Î² : Type*} â†’ (Î± â†’ Î²) â†’ Filter Î± â†’ Filter Î² â†’ Prop
  /-
  `Î± = â„•` (domain type)
  `Î² = â„` (codomain type)
  `f = (fun n => â€–Xâ€– ^ n)` (the function)
  `lâ‚ = atTop` (filter on â„• representing "as n â†’ âˆ")
  `lâ‚‚ = (ğ“ 0)` (filter on â„ representing "neighborhoods of 0")
  -/
  have h_geom : @Tendsto â„• â„ (fun n => â€–Xâ€– ^ n) atTop (ğ“ 0) :=
    -- have `h: â€–Xâ€– < 1`, `norm_nonneg X : 0 â‰¤ â€–Xâ€–`
    -- `Tendsto.pow_atTop_nhds_zero_of_lt_one` : `â€–Xâ€–^n` tends to 0 as n â†’ âˆ
    tendsto_pow_atTop_nhds_zero_of_lt_one (norm_nonneg X) h

  -- Again expand `tendsto` into Îµ/Î´ language
  rw [Metric.tendsto_atTop] at h_geom
  -- `h_geom` : âˆ€ Îµ > 0, âˆƒ N, âˆ€ n â‰¥ N, dist (â€–Xâ€– ^ n) 0 < Îµ
  -- `h_geom Îµ hÎµ` : âˆƒ N, âˆ€ n â‰¥ N, dist (â€–Xâ€– ^ n) 0 < Îµ
  -- `obtain âŸ¨N, hNâŸ© := h_geom Îµ hÎµ` : extracts the *witness* `N` and the property `hN` from the existential quantifier
  -- where `hN` is âˆ€ n â‰¥ N, dist (â€–Xâ€– ^ n) 0 < Îµ
  -- In human language,
  -- `obtain` extracts variables from an existing hypothesis
  -- `intro` introduces new variables from the goal
  obtain âŸ¨N, hNâŸ© := h_geom Îµ hÎµ
  -- `use N` : chooses the witness `N` for the existential quantifier in the goal
  use N
  intro n hn
  -- Debug: Check what hN n hn produces
  have debug_result := hN n hn
  calc â€–X ^ nâ€– â‰¤ â€–Xâ€– ^ n := by exact norm_pow_le_pow_norm X n
      _ < Îµ :=
      by simpa using hN n hn



/-
**Telescoping Left Identity for Neumann Series**

Goal: (I - X) âˆ˜ (âˆ‘_{n=0}^âˆ X^n) = I when â€–Xâ€– < 1.

Proof: Contradiction via â€–(I - X) âˆ˜ S - Iâ€– = 0, using finite telescoping
(I - X) âˆ˜ (âˆ‘_{n=0}^{N-1} X^n) = I - X^N and limits X^N â†’ 0, S_N â†’ S.
-/
lemma telescoping_left {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) :
  (I - X).comp (neumannSeriesSum h) =
  I := by
  -- S = âˆ‘_{n=0}^âˆ X^n
  unfold neumannSeriesSum
  simp only [sub_comp]
  -- If â€–Xâ€– < 1, then the operator series âˆ‘ X^n is summable in the Banach space of continuous linear maps
  have h_summable := operator_series_summable_of_norm_lt_one h

  -- -- â€–(I - X) âˆ˜ S - Iâ€– = 0 â†” (I - X) âˆ˜ S - I = 0
  -- suffices â€–(I - X).comp (âˆ‘' n, X ^ n) - ContinuousLinearMap.id â„ Eâ€– = 0 by
  --   have : (I - X).comp (âˆ‘' n, X ^ n) - I = 0 :=
  --     -- â€–xâ€– = 0 â†” x = 0
  --     norm_eq_zero.mp this
  --   exact eq_of_sub_eq_zero this
  -- -- Rewrite the goal from â€–Â·â€– = 0 to Â· = 0
  -- rw [norm_eq_zero]

  -- â€–(I - X) âˆ˜ S - Iâ€– = 0 â†” (I - X) âˆ˜ S - I = 0
  suffices (I - X).comp (âˆ‘' n, X ^ n) - I = 0 by
    exact eq_of_sub_eq_zero this

  -- Proof by contradiction
  -- Turn the goal into (I - X) âˆ˜ S - I â‰  0
  by_contra h_nonzero
  have h_pos : 0 < â€–(I - X).comp (âˆ‘' n, X ^ n) - ContinuousLinearMap.id â„ Eâ€– := by
    -- `norm_pos_iff` : â€–xâ€– > 0 â†” x â‰  0
    -- `rwa` is a combination of `rw` and `assumption`
    -- Equivalently we may write
    -- rw [norm_pos_iff]
    -- exact h_nonzero
    rwa [norm_pos_iff]

  -- Set Îµ := â€–(I - X) âˆ˜ S - Iâ€– / 3; derive 3Îµ â‰¤ 2Îµ for contradiction
  set Îµ := â€–(I - X).comp (âˆ‘' n, X ^ n) - ContinuousLinearMap.id â„ Eâ€– / 3
  have hÎµ_pos : 0 < Îµ := by
    unfold Îµ
    -- `div_pos` : a/b > 0 if a > 0 and b > 0
    apply div_pos h_pos
    -- norm_num also works
    linarith

  -- Choose N s.t. â€–S_N - Sâ€– small and â€–X^Nâ€– small
  -- `specialize` plugs in specific values into a universally quantified hypothesis
  -- `div_pos` : a/b > 0 if a > 0 and b > 0
  -- `hÎµ_pos` : 0 < Îµ
  -- `lt_max_of_lt_right zero_lt_one` : {a b c : Î±} (h : a < c) : a < max b c
  -- which yields 0 < max â€–I-Xâ€– 1
  set Îµ' := Îµ / max â€–ContinuousLinearMap.id â„ E - Xâ€– 1
  have h_partial_local := h_partial h Îµ' (div_pos hÎµ_pos (lt_max_of_lt_right zero_lt_one))
  have h_zero_lim_local := h_zero_lim h Îµ hÎµ_pos
  obtain âŸ¨Nâ‚, hNâ‚âŸ© := h_partial_local -- hNâ‚ : âˆ€ n â‰¥ Nâ‚, â€–S_N - Sâ€– < Îµ/(max â€–I-Xâ€– 1)
  obtain âŸ¨Nâ‚‚, hNâ‚‚âŸ© := h_zero_lim_local -- hNâ‚‚ : âˆ€ n â‰¥ Nâ‚‚, â€–X^Nâ€– < Îµ

  set N := max Nâ‚ Nâ‚‚
  have h_approx := hNâ‚ N (le_max_left _ _)   -- â€–S_N - Sâ€– < Îµ/(max â€–I-Xâ€– 1)
  have h_small := hNâ‚‚ N (le_max_right _ _)    -- â€–X^Nâ€– < Îµ

  -- 3Îµ = â€–(I - X) âˆ˜ S - Iâ€–
  have : 3 * Îµ = â€–(I - X).comp (âˆ‘' n, X ^ n) - ContinuousLinearMap.id â„ Eâ€– := by
    unfold Îµ
    field_simp

  -- Main inequality: 3Îµ â‰¤ 2Îµ via triangle inequality and telescoping
  have h_ineq : 3 * Îµ â‰¤ 2 * Îµ := by
    calc 3 * Îµ = â€–(I - X).comp (âˆ‘' n, X ^ n) - ContinuousLinearMap.id â„ Eâ€–
              := by exact this
        -- â€–A - Câ€– â‰¤ â€–A - Bâ€– + â€–B - Câ€– where A = (I-X)âˆ˜S, B = (I-X)âˆ˜S_N, C = I
        _ â‰¤ â€–(I - X).comp (âˆ‘' n, X ^ n) -
              (I - X).comp (âˆ‘ n âˆˆ Finset.range N, X ^ n)â€– +
            â€–(I - X).comp (âˆ‘ n âˆˆ Finset.range N, X ^ n) -
              ContinuousLinearMap.id â„ Eâ€– := by
          have h_tri : âˆ€ (x y z : E â†’L[â„] E), â€–x - zâ€– â‰¤ â€–x - yâ€– + â€–y - zâ€– := by
            intros x y z
            calc â€–x - zâ€– = â€–(x - y) + (y - z)â€– := by abel_nf
                  _ â‰¤ â€–x - yâ€– + â€–y - zâ€– := by exact norm_add_le _ _
          exact h_tri _ _ _
        -- Linearity: (I-X)âˆ˜(S - S_N); finite telescoping: (I-X)âˆ˜S_N = I - X^N
        _ = â€–(I - X).comp ((âˆ‘' n, X ^ n) - âˆ‘ n âˆˆ Finset.range N, X ^ n)â€– +
            â€–ContinuousLinearMap.id â„ E - X ^ N - ContinuousLinearMap.id â„ Eâ€– := by
          -- `comp_sub` : f.comp (g - h) = f.comp g - f.comp h
          rw [â†comp_sub, finite_telescoping N]
        -- Submultiplicativity: â€–A âˆ˜ Bâ€– â‰¤ â€–Aâ€– Â· â€–Bâ€–; â€–-X^Nâ€– = â€–X^Nâ€–
        _ â‰¤ â€–ContinuousLinearMap.id â„ E - Xâ€– * â€–(âˆ‘' n, X ^ n) - âˆ‘ n âˆˆ Finset.range N, X ^ nâ€– +
            â€–X ^ Nâ€– := by
          gcongr
            -- `opNorm_comp_le` : â€–f âˆ˜ gâ€– â‰¤ â€–fâ€– Â· â€–gâ€–
          Â· exact ContinuousLinearMap.opNorm_comp_le _ _
            -- `norm_neg` : â€–-xâ€– = â€–xâ€–
          Â· simp [norm_neg]
        -- Apply convergence bounds: â€–S - S_Nâ€– < Îµ/(max â€–I-Xâ€– 1), â€–X^Nâ€– < Îµ
        _ â‰¤ â€–ContinuousLinearMap.id â„ E - Xâ€– *
            (Îµ / max â€–ContinuousLinearMap.id â„ E - Xâ€– 1) +
            Îµ := by
          gcongr
          Â· rw [norm_sub_rev]
            exact le_of_lt h_approx
        -- â€–I-Xâ€– Â· (Îµ/max â€–I-Xâ€– 1) â‰¤ Îµ
        _ â‰¤ Îµ + Îµ := by
          -- cancels the Îµ from both sides
          gcongr
          -- â€–I - Xâ€– * (Îµ / max â€–I - Xâ€– 1) â‰¤ Îµ
          calc â€–ContinuousLinearMap.id â„ E - Xâ€– * (Îµ / max â€–ContinuousLinearMap.id â„ E - Xâ€– 1)
              â‰¤ max â€–ContinuousLinearMap.id â„ E - Xâ€– 1 * (Îµ / max â€–ContinuousLinearMap.id â„ E - Xâ€– 1) := by
                -- change the goal to Â· â‰¤ max Â· Â·
                gcongr
                exact le_max_left _ _
            _ = Îµ := by
              field_simp
        _ = 2 * Îµ := by ring

  -- The fact are we are contradicting
  have : 3 * Îµ > 2 * Îµ := by
    linarith [hÎµ_pos]

  linarith [h_ineq, this]




/--
**Commutativity of Neumann Series**: (I - X) âˆ˜ S = S âˆ˜ (I - X) where S = âˆ‘_{n=0}^âˆ X^n.

Proof: Both sides equal the identity by telescoping_left, hence they're equal.
-/
lemma neumann_comm {X : E â†’L[â„] E} {N : â„•} (h : â€–Xâ€– < 1) :
  (I - X).comp (neumannSeriesSum h) =
  (neumannSeriesSum h).comp (I - X) := by
  -- unfold neumannSeriesSum
  have h_summable := operator_series_summable_of_norm_lt_one h
  simp only [sub_comp, id_comp, comp_sub, comp_id, sub_right_inj]

  -- Turn operator = zero to norm = zero in the goal
  suffices â€–X.comp (neumannSeriesSum h) - (neumannSeriesSum h).comp Xâ€– = 0 by
    haveI : X.comp (neumannSeriesSum h) - (neumannSeriesSum h).comp X = 0 :=
      norm_eq_zero.mp this
    exact eq_of_sub_eq_zero this


  -- Rewrite goal to apply `rw h_parts`, which implcicitly rewrite it back
  -- have goal_rewrite : â€–X ((âˆ‘' (n : â„•), X ^ n) x) - (âˆ‘' (n : â„•), X ^ n) (X x)â€– =
  --                  â€–X ((neumannSeriesSum h) x) - (neumannSeriesSum h) (X x)â€– := by
  --   unfold neumannSeriesSum
  --   rfl
  -- rw [goal_rewrite]

  -- Break series into partial sums + tail, unfold `neumannSeriesSum`
  -- uses `{N : â„•}`
  have h_parts : neumannSeriesSum h =
    (âˆ‘ n âˆˆ Finset.range N, X ^ n) +
    (âˆ‘' n : â„•, X ^ (n + N)) := by
    unfold neumannSeriesSum
    -- (âˆ‘ i âˆˆ range k, f i) + âˆ‘' i, f (i + k) = âˆ‘' i, f i
    rw [â† h_summable.sum_add_tsum_nat_add N]
    -- Or equivalently
    -- exact (hSummable.sum_add_tsum_nat_add N).symm
  rw [h_parts]


  have X_commutes_with_powers {X : E â†’L[â„] E} (n : â„•) (x : E) :
    X ((X ^ n) x) = (X ^ n) (X x) := by
    induction n with
    | zero => simp [pow_zero]
    | succ m ih =>
      simp only [pow_succ', coe_mul, Function.comp_apply]
      rw [ih]

  -- First lift your pointwise lemma to operator level
  have X_comm_pow_op : âˆ€ n : â„•, X.comp (X ^ n) = (X ^ n).comp X := by
    intro n
    ext x
    exact X_commutes_with_powers n x


  haveI : X.comp (âˆ‘ n âˆˆ Finset.range N, X ^ n + âˆ‘' (n : â„•), X ^ (n + N)) -
    (âˆ‘ n âˆˆ Finset.range N, X ^ n + âˆ‘' (n : â„•), X ^ (n + N)).comp X =
      X.comp (âˆ‘ n âˆˆ Finset.range N, X ^ n) + X.comp (âˆ‘' (n : â„•), X ^ (n + N)) -
      ((âˆ‘ n âˆˆ Finset.range N, X ^ n).comp X + (âˆ‘' (n : â„•), X ^ (n + N)).comp X) := by
    rw [comp_add, add_comp]
  rw [this]

  haveI : X.comp (âˆ‘ n âˆˆ Finset.range N, X ^ n) + X.comp (âˆ‘' (n : â„•), X ^ (n + N)) -
    ((âˆ‘ n âˆˆ Finset.range N, X ^ n).comp X + (âˆ‘' (n : â„•), X ^ (n + N)).comp X) =
      (X.comp (âˆ‘ n âˆˆ Finset.range N, X ^ n) - (âˆ‘ n âˆˆ Finset.range N, X ^ n).comp X) +
      (X.comp (âˆ‘' (n : â„•), X ^ (n + N)) - (âˆ‘' (n : â„•), X ^ (n + N)).comp X) := by
    abel
  rw [this]

  -- Step 3: Show each difference is zero
  haveI : X.comp (âˆ‘ n âˆˆ Finset.range N, X ^ n) - (âˆ‘ n âˆˆ Finset.range N, X ^ n).comp X = 0 := by
    rw [comp_finset_sum, finset_sum_comp]
    simp_rw [sub_eq_zero]
    ext x
    simp only [coe_sum', Finset.sum_apply, comp_apply]
    -- Use your X_commutes_with_powers lemma
    simp only [X_commutes_with_powers]
  rw [this]
  simp only [zero_add]

  -- convert the goal back
  rw [norm_eq_zero]


  have h_summable_shifted : Summable fun n => X ^ (n + N) := by
    -- The tail of a summable series is summable
    rw [summable_nat_add_iff N]
    exact h_summable

  ext x

  -- Need pointwise summability for x
  have h_summable_shifted_x : Summable (fun n => (X ^ (n + N)) x) := by
    apply Summable.of_norm
    -- Just use that â€–X^(n+N) xâ€– â‰¤ â€–Xâ€–^(n+N) â€–xâ€–
    have h_bound : âˆ€ n, â€–(X ^ (n + N)) xâ€– â‰¤ â€–Xâ€– ^ (n + N) * â€–xâ€– := fun n =>
      calc â€–(X ^ (n + N)) xâ€–
        â‰¤ â€–X ^ (n + N)â€– * â€–xâ€– := ContinuousLinearMap.le_opNorm _ _
        _ â‰¤ â€–Xâ€– ^ (n + N) * â€–xâ€– := by gcongr; exact norm_pow_le_pow_norm X (n + N)

    apply Summable.of_nonneg_of_le (fun _ => norm_nonneg _) h_bound
    -- The geometric series âˆ‘ â€–Xâ€–^(n+N) * â€–xâ€– is summable
    have : Summable fun n => â€–Xâ€– ^ (n + N) * â€–xâ€– := by
      apply Summable.mul_right
      -- Cloude kept using `â† summable_nat_add_iff N` instead of `summable_nat_add_iff N` ..confusing
      rw [summable_nat_add_iff N]
      rw [summable_geometric_iff_norm_lt_one]
      simpa using h
    exact this

  -- Goal âŠ¢ âˆ‘' (n : â„•), (X ^ (n + N)) (X x) = (âˆ‘' (n : â„•), X ^ (n + N)) (X x)
  simp only [comp_apply, sub_apply, zero_apply]


  have h_step1 : X (âˆ‘' n, (X ^ (n + N)) x) = âˆ‘' n, X ((X ^ (n + N)) x) := by
        -- Use HasSum.map for continuous linear maps
        have h_hassum := h_summable_shifted_x.hasSum
        have h_mapped := h_hassum.map X (ContinuousLinearMap.continuous X)
        exact h_mapped.tsum_eq.symm

  have h_step2 : âˆ‘' n, X ((X ^ (n + N)) x) = âˆ‘' n, (X ^ (n + N)) (X x) := by
      congr 1
      ext n
      exact X_commutes_with_powers (n + N) x

  have h_summable : Summable (fun n => X ^ n) :=
      operator_series_summable_of_norm_lt_one (X := X) h

  have h_summable_shifted : Summable (fun n => X ^ (n + N)) :=
    (summable_nat_add_iff N).2 h_summable

  -- evaluate the operator-valued tsum at x using the evaluation CLM, not `.apply`
  have h_eval :
    ((âˆ‘' n, X ^ (n + N)) : E â†’L[â„] E) x
      = âˆ‘' n, (X ^ (n + N)) x :=
    (ContinuousLinearMap.map_tsum
      (Ï† := ContinuousLinearMap.apply (ğ•œ := â„) (E := E) (Fâ‚— := E) x)
      (hf := h_summable_shifted))

  have tsum_apply_op :
  (âˆ‘' n, X ^ (n + N)) x = âˆ‘' n, (X ^ (n + N)) x := by
    -- goal is just â€œlhs âˆ’ rhs = 0â€
    rw [h_eval]
    -- simp only [sub_self]

  have h_summable_alias {X : E â†’L[â„] E} (h : â€–Xâ€– < 1): Summable (fun n => X ^ n) :=
      operator_series_summable_of_norm_lt_one (X := X) h

  have h_summable_shifted_alias {X : E â†’L[â„] E} (h : â€–Xâ€– < 1): Summable (fun n => X ^ (n + N)) := by
    -- The tail of a summable series is summable
    rw [summable_nat_add_iff N]
    exact h_summable_alias h

  have h_eval_alias {X : E â†’L[â„] E} {x : E} (h : â€–Xâ€– < 1):
    ((âˆ‘' n, X ^ (n + N)) : E â†’L[â„] E) x
      = âˆ‘' n, (X ^ (n + N)) x :=
    (ContinuousLinearMap.map_tsum
      (Ï† := ContinuousLinearMap.apply (ğ•œ := â„) (E := E) (Fâ‚— := E) x)
      (hf := h_summable_shifted_alias h))

  have tsum_apply_op_alias {X : E â†’L[â„] E} {x : E} (h : â€–Xâ€– < 1):
    (âˆ‘' n, X ^ (n + N)) x = âˆ‘' n, (X ^ (n + N)) x := by
    rw [h_eval_alias h]

  -- rw [sub_eq_zero] at tsum_apply_op
  rw [sub_eq_zero]
  -- Now the calculation works
  calc X ((âˆ‘' n, X ^ (n + N)) x)
      = X (âˆ‘' n, (X ^ (n + N)) x) := by rw [tsum_apply_op]
      _ = âˆ‘' n, X ((X ^ (n + N)) x) := ContinuousLinearMap.map_tsum X h_summable_shifted_x
      _ = âˆ‘' n, (X ^ (n + N)) (X x) := by
        -- Explicitly provide X when using X_commutes_with_powers
        congr 1
      _ = (âˆ‘' n, X ^ (n + N)) (X x) := by
        -- `{X : E â†’L[â„] E} {x : E}` in `tsum_apply_op` allows us to use it here
        -- simp [tsum_apply_op_alias]
        rw [tsum_apply_op_alias h]




section fold
  -- -- X distributes over convergent sums
  -- have h_main_calc : X (âˆ‘' n, (X ^ (n + N)) x) = (âˆ‘' n, X ^ (n + N)) (X x) := by
  --   -- Step 1: Use the fact that X is a continuous linear map to pull it inside the infinite sum
  --   have h_step1 : X (âˆ‘' n, (X ^ (n + N)) x) = âˆ‘' n, X ((X ^ (n + N)) x) := by
  --     -- Use HasSum.map for continuous linear maps
  --     have h_hassum := h_summable_shifted_x.hasSum
  --     have h_mapped := h_hassum.map X (ContinuousLinearMap.continuous X)
  --     exact h_mapped.tsum_eq.symm

  -- -- Step 2: Use commutativity of X with powers pointwise
  -- have h_step2 : âˆ‘' n, X ((X ^ (n + N)) x) = âˆ‘' n, (X ^ (n + N)) (X x) := by
  --   congr 1
  --   ext n
  --   exact X_commutes_with_powers (n + N) x

  -- -- Step 3: Use tsum_apply to convert back to operator application
  -- have h_step3 : âˆ‘' n, (X ^ (n + N)) (X x) = (âˆ‘' n, X ^ (n + N)) (X x) := by
  --   rw [â† tsum_apply]
  --   -- Need to show the operator series is summable
  --   exact h_summable_shifted

  -- -- rw [h_step1, h_step2, h_step3]




  -- ext x
  -- -- Show finite part commutes (contributes 0)
  -- have h_finite_comm {N : â„•} :
  --   X ((âˆ‘ n âˆˆ Finset.range N, X ^ n) x) - (âˆ‘ n âˆˆ Finset.range N, X ^ n) (X x) = 0 := by
  --   simp only [coe_sum', Finset.sum_apply, map_sum]
  --   -- X and X powers commute
  --   have : âˆ€ n, X ((X ^ n) x) = (X ^ n) (X x) := by
  --     intro n
  --     induction n with
  --     | zero => simp [pow_zero]
  --     | succ m ih =>
  --       simp only [pow_succ', coe_mul, Function.comp_apply]
  --       rw [ih]
  --   -- ??????????????????
  --   rw [sub_eq_zero, Finset.sum_congr rfl (fun n _ => this n)]

  -- rw [comp_apply, comp_apply]





  -- -- Distribute and regroup
  -- rw [ContinuousLinearMap.add_apply, ContinuousLinearMap.add_apply,
  --     map_add, add_sub_add_comm]
  -- -- Finite part is cancels
  -- rw [h_finite_comm, zero_add]




  -- -- Partial sum convergence: âˆ€ Îµ > 0, âˆƒ N, âˆ€ n â‰¥ N: â€–S_n - Sâ€– < Îµ
  -- have h_partial : âˆ€ Îµ > 0, âˆƒ N, âˆ€ n â‰¥ N,
  --   â€–(âˆ‘ k âˆˆ Finset.range n, X ^ k) - âˆ‘' k, X ^ kâ€– < Îµ := by
  --   intro Îµ hÎµ
  --   have := h_summable.hasSum.tendsto_sum_nat
  --   rw [Metric.tendsto_atTop] at this
  --   exact this Îµ hÎµ


  -- -- Power vanishing: â€–Xâ€– < 1 âŸ¹ â€–X^nâ€– â‰¤ â€–Xâ€–^n â†’ 0
  -- have h_zero_lim : âˆ€ Îµ > 0, âˆƒ N, âˆ€ n â‰¥ N, â€–X ^ nâ€– < Îµ := by
  --   intro Îµ hÎµ
  --   have h_geom : Tendsto (fun n => â€–Xâ€– ^ n) atTop (ğ“ 0) :=
  --     tendsto_pow_atTop_nhds_zero_of_lt_one (norm_nonneg X) h
  --   rw [Metric.tendsto_atTop] at h_geom
  --   obtain âŸ¨N, hNâŸ© := h_geom Îµ hÎµ
  --   use N
  --   intro n hn
  --   calc â€–X ^ nâ€– â‰¤ â€–Xâ€– ^ n := by exact norm_pow_le_pow_norm X n
  --       _ < Îµ := by simpa using hN n hn
end fold



-- Not used, also defined inline in `neumann_comm`
-- Key lemma: X commutes with its powers
omit [CompleteSpace E] [Nontrivial E] in
lemma X_commutes_with_powers {X : E â†’L[â„] E} (n : â„•) (x : E) :
  X ((X ^ n) x) = (X ^ n) (X x) := by
  induction n with
  | zero => simp [pow_zero]
  | succ m ih =>
    simp only [pow_succ', coe_mul, Function.comp_apply]
    rw [ih]

-- Not used
lemma tail_series_small {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) (Îµ : â„) (hÎµ : 0 < Îµ) :
  âˆƒ N : â„•, âˆ€ n â‰¥ N, â€–âˆ‘' (k : â„•), X ^ (k + n)â€– < Îµ := by
  -- The series âˆ‘ X^k is summable
  have h_summable := operator_series_summable_of_norm_lt_one h

  -- Key insight: âˆ‘' k, X^(k+n) = âˆ‘' j, X^j - âˆ‘_{k=0}^{n-1} X^k
  -- As n â†’ âˆ, the finite sum âˆ‘_{k=0}^{n-1} X^k â†’ âˆ‘' k, X^k
  -- Therefore the tail âˆ‘' k, X^(k+n) â†’ 0

  -- Use the convergence of partial sums to the infinite sum
  have h_conv : Tendsto (fun n => âˆ‘ k âˆˆ Finset.range n, X ^ k) atTop (ğ“ (âˆ‘' k, X ^ k)) :=
    h_summable.hasSum.tendsto_sum_nat

  -- This means the tail gets arbitrarily small
  rw [Metric.tendsto_atTop] at h_conv
  obtain âŸ¨N, hNâŸ© := h_conv Îµ hÎµ

  use N
  intro n hn

  -- Key equality: tail series = total series - partial sum
  have tail_eq : âˆ‘' (k : â„•), X ^ (k + n) = âˆ‘' k, X ^ k - âˆ‘ k âˆˆ Finset.range n, X ^ k := by
    rw [â† h_summable.sum_add_tsum_nat_add n]
    abel

  rw [tail_eq]
  -- hN gives us: dist (âˆ‘ k âˆˆ Finset.range n, X ^ k) (âˆ‘' k, X ^ k) < Îµ
  -- We need: â€–âˆ‘' k, X ^ k - âˆ‘ k âˆˆ Finset.range n, X ^ kâ€– < Îµ
  rw [norm_sub_rev]  -- Flip the order to match hN
  exact hN n hn



section fold
-- -- Lemma: X distributes over infinite sums
-- lemma X_tsum_distribute {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) (N : â„•) (x : E) :
--   X ((âˆ‘' (n : â„•), X ^ (n + N)) x) = (âˆ‘' (n : â„•), X ^ (n + N + 1)) x := by
--   -- First establish that the series is summable
--   have h_summable_shifted : Summable (fun n => X ^ (n + N)) := by
--     -- Use the fact that if âˆ‘ X^n is summable, then so is âˆ‘ X^(n+N)
--     have h_orig := operator_series_summable_of_norm_lt_one h
--     exact h_orig.comp_injective (add_left_injective N)

--   -- The vector series is also summable
--   have h_summable_x : Summable (fun n => (X ^ (n + N)) x) := by
--     -- First show the majorizing series is summable
--     have h_majorizing : Summable (fun n => â€–X ^ (n + N)â€– * â€–xâ€–) := by
--       apply Summable.mul_right
--       -- The series of norms is summable by our earlier lemma applied to the shifted series
--       have h_norm_summable : Summable (fun n => â€–X ^ (n + N)â€–) := by
--         -- Apply norm bound and comparison test
--         apply Summable.of_nonneg_of_le
--         Â· intro n
--           exact norm_nonneg _
--         Â· intro n
--           exact norm_pow_le_pow_norm X (n + N)
--         Â· -- The geometric series âˆ‘ â€–Xâ€–^(n+N) is summable
--           have h_geom_shifted : Summable (fun n => â€–Xâ€– ^ (n + N)) := by
--             -- Use the fact that âˆ‘ â€–Xâ€–^k is summable, so âˆ‘ â€–Xâ€–^(k+N) is also summable
--             have h_geom_orig : Summable (fun k => â€–Xâ€– ^ k) := by
--               rw [summable_geometric_iff_norm_lt_one]
--               simp only [Real.norm_eq_abs, abs_of_nonneg (norm_nonneg X)]
--               exact h
--             exact h_geom_orig.comp_injective (add_left_injective N)
--           exact h_geom_shifted
--       exact h_norm_summable
--     -- Now apply the norm bound
--     apply Summable.of_norm_bounded h_majorizing
--     intro n
--     exact ContinuousLinearMap.le_opNorm _ _

--   -- Apply the continuity of X to distribute over the infinite sum
--   have h_rewrite : X ((âˆ‘' (n : â„•), X ^ (n + N)) x) = âˆ‘' (n : â„•), X ((X ^ (n + N)) x) := by
--     -- Change the bound variable to match what map_tsum expects
--     show X ((âˆ‘' (n : â„•), X ^ (n + N)) x) = âˆ‘' (n : â„•), X ((X ^ (n + N)) x)
--     convert ContinuousLinearMap.map_tsum X h_summable_x
--     sorry


--   rw [h_rewrite]
--   sorry




-- -- Lemma: Reindexing the tail series
-- lemma tail_series_reindex {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) (N : â„•) (x : E) :
--   (âˆ‘' (n : â„•), X ^ (n + N + 1)) x = (âˆ‘' (n : â„•), X ^ (n + N)) (X x) := by
--   sorry



-- -- Main theorem using epsilon argument
-- lemma neumann_tail_comm_epsilon {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) (N : â„•) (x : E) :
--   â€–X ((âˆ‘' (n : â„•), X ^ (n + N)) x) - (âˆ‘' (n : â„•), X ^ (n + N)) (X x)â€– = 0 := by
--   -- Strategy: Show it's less than any Îµ > 0
--   suffices âˆ€ Îµ > 0, â€–X ((âˆ‘' (n : â„•), X ^ (n + N)) x) - (âˆ‘' (n : â„•), X ^ (n + N)) (X x)â€– â‰¤ Îµ by
--     -- If â€–vâ€– â‰¤ Îµ for all Îµ > 0, then â€–vâ€– = 0
--     by_contra h_ne
--     set d := â€–X ((âˆ‘' (n : â„•), X ^ (n + N)) x) - (âˆ‘' (n : â„•), X ^ (n + N)) (X x)â€– with hd
--     have h_pos : 0 < d := by
--       rw [hd]  -- Now substituting d = â€–...â€– into 0 < d
--       exact lt_of_le_of_ne (norm_nonneg _) (Ne.symm h_ne)
--     -- Take Îµ = d/2
--     have h_half : d â‰¤ d / 2 := by
--       rw [hd]  -- Substitute d = â€–...â€–
--       exact this (d / 2) (half_pos h_pos)
--     -- But d â‰¤ d/2 is impossible when d > 0
--     have : d < d := calc
--       d â‰¤ d / 2 := h_half
--       _ < d := half_lt_self h_pos
--     exact lt_irrefl d this

--   intro Îµ hÎµ
--   -- Use the distribution and reindexing lemmas
--   rw [X_tsum_distribute h N x]
--   rw [tail_series_reindex h N x]
--   -- Now both sides are equal, so the difference is 0
--   simp only [sub_self, norm_zero]
--   exact le_of_lt hÎµ
end fold



lemma telescoping_right {X : E â†’L[â„] E} {N : â„•} (h : â€–Xâ€– < 1) :
  (neumannSeriesSum h).comp (I - X) =
  I := by
  rw [â† neumann_comm (N:=N) h]
  exact telescoping_left h



/--
**Main Neumann Series Theorem (IsUnit version)**

If `â€–I - Bâ€– < 1` for a continuous linear map B on a Banach space, then `B` is a unit (invertible).
We construct the unit explicitly using the Neumann series as the inverse.
-/
theorem isUnit_of_norm_sub_id_lt_one {B : E â†’L[â„] E} {N : â„•}
  (h : â€–(I) - Bâ€– < 1) :
  IsUnit B := by
  classical
  -- set `X := id - B`; the inverse will be `S := âˆ‘ X^n`, and `B = id - X`
  set X := (I - B)
  have hX : â€–Xâ€– < 1 := by simpa [X]
  have hB : B = I - X := by
    simp [X]
  -- Candidate inverse:
  let S := neumannSeriesSum hX
  -- Show left/right inverse identities using the telescoping lemmas.
  have hL : (I - X).comp S = I := by
    simpa using telescoping_left (X := X) hX
  have hR : S.comp (I - X) = I := by
    simpa using telescoping_right (X := X) (N := N) hX
  -- Build a `Units` structure explicitly.
  refine âŸ¨âŸ¨B, S, ?_, ?_âŸ©, rflâŸ©
  Â· -- `B * S = 1` (multiplication is composition)
    -- `hL : (id - X) âˆ˜ S = id`, and `B = id - X`.
    -- Convert composition equality to `*` equality.
    -- `ext` to compare as maps.
    have : (B.comp S) = (I) := by simpa [hB]
      using hL
    -- turn equality of maps into equality of elements in the monoid
    simpa using this
  Â· -- `S * B = 1`
    have : (S.comp B) = (I) := by
      simpa [hB] using hR
    simpa using this

/--
Alternative version with explicit inverse construction
-/
theorem invertible_of_norm_sub_id_lt_one {B : E â†’L[â„] E} {N : â„•}
  (h : â€–(1 : E â†’L[â„] E) - Bâ€– < 1) :
  âˆƒ (B_inv : E â†’L[â„] E),
    B * B_inv = 1 âˆ§ B_inv * B = 1 := by
  have hu := isUnit_of_norm_sub_id_lt_one h (N:=N)
  obtain âŸ¨u, rflâŸ© := hu
  exact âŸ¨u.inv, u.val_inv, u.inv_valâŸ©

end NeumannSeries





/-
==============================================================================
# NONDEGENERACY AND INVERTIBILITY
==============================================================================

Definition 2.3.2 (page 20): "A point xÌƒ âˆˆ U is a nondegenerate zero of f
if f(xÌƒ) = 0 and Df(xÌƒ) is invertible."

We need to establish when Df is invertible. A key lemma is that if
â€–I - ADf(xÌ„)â€– < 1, then ADf(xÌ„) is invertible (used in proof of Theorem 2.4.2).
-/


/--
A point is a nondegenerate zero if it's a zero and the derivative is invertible.
-/
def IsNondegenerateZero (f : E â†’ E) (x : E) : Prop :=
  f x = 0 âˆ§ DifferentiableAt â„ f x âˆ§ IsUnit (fderiv â„ f x)


/-
==============================================================================
# CONTRACTION PROPERTY OF THE NEWTON-LIKE MAP
==============================================================================

From Section 2.3 (page 20): "If xÌƒ is a nondegenerate zero, then in a small
neighborhood of xÌƒ, T is a contraction mapping with small contraction constant."

The key calculation is DT(xÌƒ) = I - Df(xÌƒ)â»Â¹Df(xÌƒ) = 0 at a zero.
-/

/--
The derivative of the Newton-like map T(x) = x - A(f(x)) is DT(x) = I - Aâˆ˜Df(x).
-/
lemma deriv_newton_like_map {f : E â†’ E} {A : E â†’L[â„] E} {x : E}
  (hf : DifferentiableAt â„ f x) :
  fderiv â„ (NewtonLikeMap f A) x = id - A.comp (fderiv â„ f x) := by
  -- Use the chain rule and linearity of differentiation
  unfold NewtonLikeMap
  -- The derivative of x â†¦ x - A(f(x)) is id - A âˆ˜ Df
  calc fderiv â„ (fun x => x - A (f x)) x
      = fderiv â„ id x - fderiv â„ (A âˆ˜ f) x := by
        -- Derivative of difference is difference of derivatives
        sorry
    _ = id - A.comp (fderiv â„ f x) := by
        -- fderiv of id is id, and chain rule for A âˆ˜ f
        sorry

/-
==============================================================================
# MEAN VALUE INEQUALITY APPLICATION
==============================================================================

From Corollary 2.2.6 and the proof of Theorem 2.4.1:
We use the mean value inequality to show T maps a ball into itself and is contractive.
-/

/--
A helper lemma that applies the mean value theorem specifically for our Newton map.
This bridges between the abstract derivative bounds and concrete distance estimates.
-/
lemma newton_map_lipschitz_on_ball
  {f : E â†’ E} {A : E â†’L[â„] E} {xBar : E} {r Z_r : â„}
  (hf_diff : DifferentiableOn â„ (NewtonLikeMap f A) (closedBall xBar r))
  (hZ : âˆ€ x âˆˆ closedBall xBar r, â€–fderiv â„ (NewtonLikeMap f A) xâ€– â‰¤ Z_r) :
  âˆ€ x y âˆˆ closedBall xBar r,
    â€–NewtonLikeMap f A x - NewtonLikeMap f A yâ€– â‰¤ Z_r * â€–x - yâ€– := by
  intros x hx y hy
  -- The closed ball is convex
  haveI h_convex : Convex â„ (closedBall xBar r) := convex_closedBall xBar r
  -- Apply the mean value theorem on the convex set
  apply h_convex.norm_image_sub_le_of_norm_fderivWithin_le
  Â· exact hf_diff
  Â· intro z hz
    -- Convert fderivWithin to fderiv since we're on an open neighborhood
    rw [DifferentiableOn.fderivWithin_eq_fderiv (hf_diff)
        (isOpen_ball.mem_nhds _)] at hZ
    Â· exact hZ z hz
    Â· sorry -- Need to show z is in the interior for this conversion
  Â· exact hx
  Â· exact hy

/--
If T satisfies certain bounds, then it maps a closed ball into itself.
This is the key step in proving T has a fixed point via contraction mapping theorem.

The proof follows the structure from Theorem 2.4.1 (page 21) of the informal proof:
1. Start with â€–T(x) - xÌ„â€– and split using triangle inequality
2. Apply mean value inequality to bound â€–T(x) - T(xÌ„)â€–
3. Use the bounds Y0 and Z_r to show the result is < r
-/
lemma newton_map_preserves_ball
  {f : E â†’ E} {A : E â†’L[â„] E} {xBar : E} {r Y0 Z_r : â„}
  (hf_diff : DifferentiableOn â„ (NewtonLikeMap f A) (closedBall xBar r))
  (hr : 0 < r)
  (hY0 : â€–NewtonLikeMap f A xBar - xBarâ€– â‰¤ Y0)
  (hZ : âˆ€ x âˆˆ closedBall xBar r, â€–fderiv â„ (NewtonLikeMap f A) xâ€– â‰¤ Z_r)
  (hp : Z_r * r + Y0 < r) :
  MapsTo (NewtonLikeMap f A) (closedBall xBar r) (closedBall xBar r) := by
  -- Unpack what we need to prove: for any x in the ball, T(x) is also in the ball
  intro x hx
  rw [mem_closedBall] at hx âŠ¢

  -- Step 1: Apply triangle inequality to split â€–T(x) - xÌ„â€–
  -- This is equation (2.19) in the informal proof
  calc â€–NewtonLikeMap f A x - xBarâ€–
      â‰¤ â€–NewtonLikeMap f A x - NewtonLikeMap f A xBarâ€– +
        â€–NewtonLikeMap f A xBar - xBarâ€– :=
          norm_sub_le _ _  -- Triangle inequality
    _ â‰¤ Z_r * â€–x - xBarâ€– + Y0 := by
        apply add_le_add
        Â· -- First term: Apply our Lipschitz lemma
          exact newton_map_lipschitz_on_ball hf_diff hZ x hx xBar
            (mem_closedBall_self (le_of_lt hr))
        Â· -- Second term: Direct from hypothesis hY0
          exact hY0
    _ â‰¤ Z_r * r + Y0 := by
        -- Since x âˆˆ closedBall xBar r, we have â€–x - xBarâ€– â‰¤ r
        gcongr
        exact hx
    _ < r := hp  -- This is our hypothesis that p(r) < 0 implies this inequality

/-
==============================================================================
# RADII POLYNOMIAL SETUP
==============================================================================

From Theorem 2.4.2 (page 22): The radii polynomial approach with bounds Y0, Z0, Z2.
-/

/--
Radii polynomial data structure with the three key bounds.
Y0 bounds â€–Af(xÌ„)â€–, Z0 bounds â€–I - ADf(xÌ„)â€–, Z2 bounds the derivative variation.
-/
structure RadiiPolynomialData : Type where
  Y0 : â„  -- Bound on â€–Af(xÌ„)â€–
  Z0 : â„  -- Bound on â€–I - ADf(xÌ„)â€–
  Z2 : â„ â†’ â„  -- Bound on â€–A[Df(c) - Df(xÌ„)]â€–/r for c âˆˆ B_r(xÌ„)
  Y0_nonneg : 0 â‰¤ Y0
  Z0_nonneg : 0 â‰¤ Z0
  Z2_nonneg : âˆ€ {r}, 0 < r â†’ 0 â‰¤ Z2 r

namespace RadiiPolynomialData

/--
The combined bound Z(r) = Zâ‚€ + Zâ‚‚(r)Â·r from equation (2.18).
-/
def Z_combined (data : RadiiPolynomialData) (r : â„) : â„ :=
  data.Z0 + (data.Z2 r) * r

/--
The radii polynomial p(r) = Zâ‚‚(r)rÂ² - (1 - Zâ‚€)r + Yâ‚€ from equation (2.17).
-/
def radiusPolynomial (data : RadiiPolynomialData) (r : â„) : â„ :=
  (data.Z2 r) * r^2 - (1 - data.Z0) * r + data.Y0

/--
Alternative formulation: p(r) = (Z(r) - 1)r + Yâ‚€.
This shows the connection to the contraction condition Z(r) < 1.
-/
lemma radiusPolynomial_rw (data : RadiiPolynomialData) (r : â„) :
  data.radiusPolynomial r = (data.Z_combined r - 1) * r + data.Y0 := by
  unfold radiusPolynomial Z_combined
  ring

/--
If p(r) < 0, then Z(r) < 1 (contraction) and the ball is mapped into itself.
-/
lemma radiusPolynomial_negative_implies_contraction
  {data : RadiiPolynomialData} {r : â„}
  (hr : 0 < r) (hp : data.radiusPolynomial r < 0) :
  data.Z_combined r < 1 âˆ§ data.Z_combined r * r + data.Y0 < r := by
  rw [radiusPolynomial_rw] at hp
  constructor
  Â· -- Prove Z(r) < 1
    haveI : (data.Z_combined r - 1) * r + data.Y0 < 0 := hp
    haveI : 0 â‰¤ data.Y0 := data.Y0_nonneg
    -- Since Y0 â‰¥ 0 and the sum is < 0, we need (Z(r) - 1) * r < 0
    haveI : (data.Z_combined r - 1) * r < 0 := by linarith
    -- Since r > 0, we need Z(r) - 1 < 0, hence Z(r) < 1
    haveI : data.Z_combined r - 1 < 0 := by
      -- Assume `Z(r) - 1 â‰¥ 0`
      by_contra h_not
      haveI : 0 â‰¤ data.Z_combined r - 1 := by linarith
      -- Then `(Z(r) - 1) * r â‰¥ 0` since `r > 0`.
      -- `this` is the immediate conclusion 0 â‰¤ data.Z_combined r - 1
      -- hr.le is `r â‰¤ 0` relaxed from `0 < r`
      haveI : 0 â‰¤ (data.Z_combined r - 1) * r := mul_nonneg this hr.le
      linarith
    linarith

  Â· -- Prove Z(r) * r + Y0 < r
    calc data.Z_combined r * r + data.Y0
        = (data.Z_combined r - 1) * r + r + data.Y0 := by ring
      _ = ((data.Z_combined r - 1) * r + data.Y0) + r := by ring
      _ < 0 + r := by linarith [hp]
      _ = r := by ring

end RadiiPolynomialData

/-
==============================================================================
# MAIN RADII POLYNOMIAL THEOREM (Theorem 2.4.2)
==============================================================================

This is the main result that guarantees existence of a unique nondegenerate zero.
-/

/--
Main radii polynomial theorem for proving existence of nondegenerate zeros.
If the radii polynomial has a negative value at some râ‚€ > 0, then there exists
a unique zero xÌƒ in the ball B_râ‚€(xÌ„), and this zero is nondegenerate.
-/
theorem radii_polynomial_theorem
  {f : E â†’ E} {xBar : E} {A : E â†’L[â„] E}
  (hf_diff : âˆ€ x, DifferentiableAt â„ f x)
  (data : RadiiPolynomialData)
  -- The three key bounds from equations (2.14), (2.15), (2.16)
  (hY0 : â€–A (f xBar)â€– â‰¤ data.Y0)
  (hZ0 : â€–id - A.comp (fderiv â„ f xBar)â€– â‰¤ data.Z0)
  (hZ2 : âˆ€ (c : E) (r : â„), c âˆˆ closedBall xBar r â†’ 0 < r â†’
         â€–A.comp ((fderiv â„ f c) - (fderiv â„ f xBar))â€– â‰¤ data.Z2 r * r)
  -- If the polynomial is negative at some râ‚€
  {r0 : â„} (hr0_pos : 0 < r0)
  (hp_neg : data.radiusPolynomial r0 < 0) :
  -- Then there exists a unique nondegenerate zero in the ball
  âˆƒ! (x_tilde : E), x_tilde âˆˆ closedBall xBar r0 âˆ§
                     IsNondegenerateZero f x_tilde := by
  -- Step 1: Show that T = NewtonLikeMap f A is a contraction on closedBall xBar r0

  -- From p(râ‚€) < 0, we get Z(râ‚€) < 1 and the self-mapping property
  obtain âŸ¨hZ_lt_one, hself_mapâŸ© :=
    data.radiusPolynomial_negative_implies_contraction hr0_pos hp_neg

  -- Step 2: Apply the Contraction Mapping Theorem
  -- We need to show:
  -- (a) T maps the ball into itself
  -- (b) T is a contraction with constant < 1
  -- (c) The ball is complete (follows from E being complete)

  sorry -- This requires assembling all the pieces with the contraction mapping theorem

/-
==============================================================================
# CONVERGENCE TO NEWTON'S METHOD
==============================================================================

From Section 2.5 (mentioned in the user's request):
If xÌƒ is a zero, Df(xÌƒ) is invertible, xÌ„ is sufficiently close to xÌƒ,
and we have sufficient computational resources, then the radii polynomial
approach guarantees finding xÌƒ.
-/

/--
If the initial guess is sufficiently close to a nondegenerate zero,
then the radii polynomial approach succeeds.
-/
theorem radii_success_near_nondegenerate_zero
  {f : E â†’ E} {x_tilde xBar : E} {A : E â†’L[â„] E}
  (hf_diff : âˆ€ x, DifferentiableAt â„ f x)
  (h_zero : IsNondegenerateZero f x_tilde)
  (hA_approx : â€–A - (fderiv â„ f x_tilde).inverseâ€– < Îµ)
  (h_close : â€–xBar - x_tildeâ€– < Î´)
  -- For sufficiently small Îµ and Î´
  (hÎµ : Îµ > 0) (hÎ´ : Î´ > 0) (h_small : Îµ * Î´ < 1/4) :
  -- Then there exists r > 0 such that the radii polynomial is negative
  âˆƒ (r : â„) (data : RadiiPolynomialData),
    0 < r âˆ§
    data.radiusPolynomial r < 0 âˆ§
    x_tilde âˆˆ closedBall xBar r := by
  -- The proof follows from continuity arguments and the fact that
  -- at a nondegenerate zero, DT(xÌƒ) = 0, making T a strong contraction nearby
  sorry
