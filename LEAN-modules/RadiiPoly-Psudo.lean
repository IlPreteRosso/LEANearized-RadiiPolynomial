/-
Lean 4.24.0-rc1 (arm64-apple-darwin), Mathlib4 (commit near 919e2972â€¦)
Tip: run `lake exe cache get` once to prefetch Mathlib artifacts.
-/

import Mathlib.Analysis.SpecificLimits.Basic
import Mathlib.Data.Setoid.Basic
import Mathlib.Dynamics.FixedPoints.Topology
import Mathlib.Topology.MetricSpace.Lipschitz
import Mathlib.Analysis.Calculus.Deriv.AffineMap
import Mathlib.Analysis.Calculus.Deriv.Comp
import Mathlib.Analysis.Calculus.Deriv.Mul
import Mathlib.Analysis.Calculus.Deriv.Slope
import Mathlib.Analysis.Normed.Group.AddTorsor
import Mathlib.Analysis.Normed.Module.Convex
import Mathlib.Analysis.RCLike.Basic
import Mathlib.Topology.Instances.RealVectorSpace
import Mathlib.Topology.LocallyConstant.Basic
import Mathlib.Analysis.Normed.Group.InfiniteSum
import Mathlib.Algebra.BigOperators.Group.Finset.Basic
import Mathlib.Analysis.Normed.Operator.ContinuousLinearMap
import Mathlib.Algebra.Module.LinearMap.Defs


open scoped Topology
open Metric Set Filter ContinuousLinearMap



/-
NormedAddCommGroup: A *normed* group is an additive group endowed with a norm for which `dist x y = â€–x - yâ€–` defines a *metric space structure*.

NormedSpace â„ E: A normed space over the reals is a *vector space over the real numbers* equipped with a norm that satisfies the properties of a norm (non-negativity, definiteness, homogeneity, and triangle inequality).

CompleteSpace E: A *complete* space is a metric space in which every Cauchy sequence converges to a limit within the space.

â‡’ E is a Banach space over â„.
-/
variable {E : Type*} [NormedAddCommGroup E] [NormedSpace â„ E] [CompleteSpace E]

/--
Newton-like map `T x = x - A (f x)` on a Banach space.
From equation (2.7) in the informal proof.
- `f` is the nonlinear map whose zeros we seek
- `A` is a linear operator (approximate inverse of Df at some point)
-/
def NewtonLikeMap (f : E â†’ E) (A : E â†’L[â„] E) (x : E) : E := x - A (f x)

/--
`closedBall x Îµ` is the set of all points `y` with `dist y x â‰¤ Îµ`.
This defines the domain where we'll prove T is a contraction.
-/
def WorkingDomain (xBar : E) (r : â„) : Set E := closedBall xBar r


section Proposition_2_3_1
/-
================================================================================
PROPOSITION 2.3.1: Equivalence between fixed points of T and zeros of f
================================================================================

From the informal proof (page 19):
"Let X and Y be vector spaces. Let U âŠ‚ X and consider f : U â†’ Y.
Assume that A: Y â†’ X is an injective linear map. Let T : U â†’ X be defined by
T(x) = x - Af(x). Then, T(xÌƒ) = xÌƒ if and only if f(xÌƒ) = 0."
-/

-- Omit `[CompleteSpace]` for this section
variable {E : Type*} [NormedAddCommGroup E] [NormedSpace â„ E]
/--
T(x) = x - A(f(x)) = 0 â†” f(x) = 0 when A is injective.
-/
lemma fixedPoint_injective_iff_zero
  {f : E â†’ E} {A : E â†’L[â„] E}
  (hA : Function.Injective A) (x : E) :
  NewtonLikeMap f A x = x â†” f x = 0 := by
  -- Unfold the definition of NewtonLikeMap: T(x) = x - A(f(x))
  unfold NewtonLikeMap

  -- T(x) = x means x - A(f(x)) = x
  -- This is equivalent to A(f(x)) = 0
  calc
    x - A (f x) = x â†” A (f x) = 0 := by
      constructor
      Â· intro h
        -- From x - A(f(x)) = x, subtract x from both sides
        have h_sub : x - (x - A (f x)) = x - x := by rw [h]
        calc
          A (f x)
            = x - (x - A (f x)) := by abel
          _ = x - x             := by rw [h_sub]
          _ = 0                 := by rw [sub_self x]
        -- linarith [h]
      Â· intro h
        -- From A(f(x)) = 0, we get x - 0 = x
        simp [h]
    _ â†” f x = 0 := by
      -- Since A is injective, A(y) = 0 implies y = 0
      constructor
      Â· intro h
        -- A is a linear map, so A(0) = 0
        haveI : A 0 = 0 := map_zero A

        -- (1) We haveI `h : A (f x) = 0`. We want to show `A (f x) = A 0`.
        -- To do this, we first flip the equality `A 0 = 0` to `0 = A 0`.
        haveI : 0 = A 0 := this.symm

        -- (2) Now we chain the two equalities together.
        -- `h` gives us `A (f x) = 0`
        -- `this` gives us `0 = A 0`
        -- By transitivity of equality, we get `A (f x) = A 0`.
        haveI : A (f x) = A 0 := h.trans this

        -- (3) Apply the injectivity of A.
        -- `hA` is the hypothesis `Function.Injective A`.
        -- By definition, this means if `A y = A z`, then `y = z`.
        -- We apply `hA` to our proof `h_eq_A_zero` to conclude `f x = 0`.
        exact hA this

      Â· intro h
        -- If f(x) = 0, then A(f(x)) = A(0) = 0
        simp [h]

end Proposition_2_3_1



/-
================================================================================
NEUMANN SERIES THEOREM FOR INVERTIBILITY
================================================================================

This section proves that operators close to the identity are invertible,
with the inverse given by the Neumann series.

We break the proof into manageable lemmas, each handling one aspect.

Note: We assume `[Nontrivial E]` throughout this section since we're working
with operators on meaningful Banach spaces where Newton's method makes sense.
In practice, spaces like â„â¿ (n â‰¥ 1), function spaces, etc. are all nontrivial.
-/
section NeumannSeries

variable {E : Type*} [NormedAddCommGroup E] [NormedSpace â„ E] [CompleteSpace E] [Nontrivial E]



omit [CompleteSpace E] in
/--
First lemma: nth powers norm submultiplicativity
of the operator norm.
-/
lemma norm_pow_le_pow_norm (X : E â†’L[â„] E) (n : â„•) :
  â€–X ^ nâ€– â‰¤ â€–Xâ€– ^ n := by
  induction n with
  | zero =>
    -- Base case: â€–X^0â€– = â€–Iâ€– = 1 = â€–Xâ€–^0
    calc
      â€–X ^ 0â€–
        -- Can I do rw here instead of simp???????
        = â€–ContinuousLinearMap.id â„ Eâ€– := by simp [pow_zero]
      -- Since E is nontrivial, we have â€–Iâ€– = 1
      _ = 1                            := by rw [ContinuousLinearMap.norm_id]
      _ = â€–Xâ€– ^ 0                      := by rw [pow_zero]
      _ â‰¤ â€–Xâ€– ^ 0                      := by exact le_rfl

  | succ m _ =>
    -- Inductive step: use submultiplicativity â€–A Bâ€– â‰¤ â€–Aâ€– â€–Bâ€–
    calc â€–X ^ (m + 1)â€– = â€–X ^ m * Xâ€– := by rw [pow_succ]
      _ â‰¤ â€–X ^ mâ€– * â€–Xâ€– := by
        -- ContinuousLinearMap forms a normed algebra where norm is submultiplicative
        -- The standard lemma for this is norm_mul_le
        exact norm_mul_le (X ^ m) X
      _ â‰¤ â€–Xâ€– ^ m * â€–Xâ€– := by
        gcongr
      _ = â€–Xâ€– ^ (m + 1) := by
        rw [pow_succ]



omit [CompleteSpace E] in
/--
Second lemma: If â€–Xâ€– < 1, then the series âˆ‘ â€–X^nâ€– is summable.
This follows by comparison with the geometric series âˆ‘ â€–Xâ€–^n.
-/
lemma norm_series_summable_of_norm_lt_one {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) :
  Summable (fun n : â„• => â€–X ^ nâ€–) := by
  -- First, get the geometric series to converge
  -- Since â€–Xâ€– is a nonnegative real, we can use it directly
  haveI h_geometric : Summable (fun n : â„• => (â€–Xâ€– : â„) ^ n) := by
    -- Apply the geometric series test
    rw [summable_geometric_iff_norm_lt_one]
    -- â€–Xâ€– is already nonnegative, so â€–â€–Xâ€–â€– = â€–Xâ€–
    simpa using h
  -- Now use comparison: â€–X^nâ€– â‰¤ â€–Xâ€–^n
  refine Summable.of_nonneg_of_le ?_ (norm_pow_le_pow_norm X) h_geometric
  -- Show each term is nonnegative (norms are always nonnegative)
  intro n
  exact norm_nonneg _



/--
Third lemma: If â€–Xâ€– < 1, then the operator series âˆ‘ X^n is summable
in the Banach space of continuous linear maps.
This uses the completeness of the space.
-/
lemma operator_series_summable_of_norm_lt_one {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) :
  Summable (fun n : â„• => X ^ n) := by
  -- In a Banach space, absolute convergence implies convergence
  -- `Summable.of_norm` turns goal from `Summable (X^n)` to `Summable (â€–X^nâ€–)`.
  apply Summable.of_norm
  exact norm_series_summable_of_norm_lt_one h



/--
Helper definition: The Neumann series sum S = âˆ‘ X^n exists when â€–Xâ€– < 1.
This sum will be shown to be the inverse of (I - X).
-/
noncomputable def neumannSeriesSum {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) : E â†’L[â„] E :=
  haveI : Summable (fun n : â„• => X ^ n) :=
  operator_series_summable_of_norm_lt_one h
  -- `âˆ‘' i, f i` is the sum of f if it exists and is unconditionally convergent, or 0 otherwise.
  âˆ‘' n : â„•, X ^ n



omit [CompleteSpace E] [Nontrivial E] in
/--
Finite telescoping: (I - X) âˆ˜ (âˆ‘_{n=0}^{N-1} X^n) = I - X^N
-/
lemma finite_telescoping {X : E â†’L[â„] E} (N : â„•) :
  (ContinuousLinearMap.id â„ E - X).comp (âˆ‘ n âˆˆ Finset.range N, X ^ n) =
   ContinuousLinearMap.id â„ E - X ^ N := by
  -- Prove equality of linear maps by showing they agree on all inputs
  ext x
  simp

  calc
    -- Goal: ((I - X) âˆ˜ S) x = (I - X) (S x)
    -- where S = âˆ‘_{n=0}^{N-1} X^n.
    -- Distribute X over the sum using linearity: X(âˆ‘X^n x) = ( âˆ‘X^{n+1} x )
    âˆ‘ n âˆˆ Finset.range N, (X ^ n) x - âˆ‘ x_1 âˆˆ Finset.range N, X ((X ^ x_1) x) =
    (âˆ‘ n âˆˆ Finset.range N, X ^ n) x - (âˆ‘ n âˆˆ Finset.range N, X ^ (n + 1)) x := by
        -- The first term is unchanged, removed from the goal by `congr 1` (`rfl`)
        congr 1
        -- Move X inside the sum
        simp [sum_apply]
        -- Rewrite X âˆ˜ (X^n) as X^{n+1}
        haveI {n : â„•} {x : E}: X ((X ^ n) x) = (X ^ (n + 1)) x := by
          rw [pow_succ', â† comp_apply]
          rfl
        simp [this]

    -- The telescoping: âˆ‘_{n=0}^{N-1} X^n x - âˆ‘_{n=0}^{N-1} X^{n+1} x = x - X^N x
    _ = x - (X ^ N) x := by
        have telescope : âˆ€ M : â„•,
          âˆ‘ n âˆˆ Finset.range M, (X ^ n) x - âˆ‘ n âˆˆ Finset.range M, (X ^ (n + 1)) x =
          (X ^ 0) x - (X ^ M) x := by
          intro M
          induction M with
          | zero      => simp
          | succ k ih =>
            -- break down a sum over k+1 terms into
            -- a sum over k terms plus the final term
            rw [Finset.sum_range_succ, Finset.sum_range_succ]
            simp
            calc
              (âˆ‘ n âˆˆ Finset.range k, (X ^ n) x) + (X ^ k) x -
              ((âˆ‘ n âˆˆ Finset.range k, (X ^ (n + 1)) x) +
              (X ^ (k + 1)) x)
              = (âˆ‘ n âˆˆ Finset.range k, (X ^ n) x) -
                (âˆ‘ n âˆˆ Finset.range k, (X ^ (n + 1)) x) +
                ((X ^ k) x - (X ^ (k + 1)) x)
              := by abel
              _ = ((X ^ 0) x - (X ^ k) x) + ((X ^ k) x - (X ^ (k + 1)) x)
                := by rw [ih]
              _ = (X ^ 0) x - (X ^ (k + 1)) x
                := by abel

        simp [telescope N]
/--
Finite telescoping - legacy version with redundant steps.
-/
-- lemma finite_telescoping_legacy {X : E â†’L[â„] E} (N : â„•) :
--   (ContinuousLinearMap.id â„ E - X).comp (âˆ‘ n âˆˆ Finset.range N, X ^ n) =
--    ContinuousLinearMap.id â„ E - X ^ N := by
--   -- Prove equality of linear maps by showing they agree on all inputs
--   ext x

--   simp
--   -- -- Simplify the goal to x - X^N x
--   -- haveI : (ContinuousLinearMap.id â„ E - X ^ N) x = x - (X ^ N) x := by
--   --   calc
--   --     (ContinuousLinearMap.id â„ E - X ^ N) x
--   --       = (ContinuousLinearMap.id â„ E) x - (X ^ N) x
--   --       := by rw [sub_apply]
--   --     _ = x - (X ^ N) x := by rw [id_apply]
--   -- rw [this]

--   calc
--     -- Goal: ((I - X) âˆ˜ S) x = (I - X) (S x)
--     -- where S = âˆ‘_{n=0}^{N-1} X^n.
--     -- ((ContinuousLinearMap.id â„ E - X).comp (âˆ‘ n âˆˆ Finset.range N, X ^ n)) x
--     --   = (ContinuousLinearMap.id â„ E - X) ((âˆ‘ n âˆˆ Finset.range N, X ^ n) x)
--     --   := by rw [ContinuousLinearMap.coe_comp', Function.comp_apply]

--     -- Apply the subtraction operator: (I - X)(S x) = (S x) - X(S x)
--     -- _ = (âˆ‘ n âˆˆ Finset.range N, X ^ n) x - X ((âˆ‘ n âˆˆ Finset.range N, X ^ n) x)
--     --   := by rw [sub_apply, id_apply]

--     -- Distribute X over the sum using linearity: X(âˆ‘X^n x) = ( âˆ‘X^{n+1} x )
--     âˆ‘ n âˆˆ Finset.range N, (X ^ n) x - âˆ‘ x_1 âˆˆ Finset.range N, X ((X ^ x_1) x) = (âˆ‘ n âˆˆ Finset.range N, X ^ n) x - (âˆ‘ n âˆˆ Finset.range N, X ^ (n + 1)) x
--       := by
--         -- The first term is unchanged, removed from the goal by `congr 1` (`rfl`)
--         congr 1
--         -- Move X inside the sum
--         simp [sum_apply]
--         -- Simplify the goal again by dropping the sum
--         -- congr
--         -- change summation index to n
--         -- ext n
--         -- Rewrite X âˆ˜ (X^n) as X^{n+1}
--         haveI {n : â„•} {x : E}: X ((X ^ n) x) = (X ^ (n + 1)) x := by
--           rw [pow_succ', â† comp_apply]
--           rfl
--         simp [this]

--     -- The telescoping: âˆ‘_{n=0}^{N-1} X^n x - âˆ‘_{n=0}^{N-1} X^{n+1} x = x - X^N x
--     _ = x - (X ^ N) x := by
--         have telescope : âˆ€ M : â„•,
--           âˆ‘ n âˆˆ Finset.range M, (X ^ n) x - âˆ‘ n âˆˆ Finset.range M, (X ^ (n + 1)) x =
--           (X ^ 0) x - (X ^ M) x := by
--           intro M
--           induction M with
--           | zero => simp
--           | succ k ih =>
--             -- break down a sum over k+1 terms into
--             -- a sum over k terms plus the final term
--             rw [Finset.sum_range_succ, Finset.sum_range_succ]
--             simp
--             calc
--               (âˆ‘ n âˆˆ Finset.range k, (X ^ n) x) + (X ^ k) x -
--               ((âˆ‘ n âˆˆ Finset.range k, (X ^ (n + 1)) x) +
--               (X ^ (k + 1)) x)
--               = (âˆ‘ n âˆˆ Finset.range k, (X ^ n) x) -
--                 (âˆ‘ n âˆˆ Finset.range k, (X ^ (n + 1)) x) +
--                 ((X ^ k) x - (X ^ (k + 1)) x)
--               := by abel
--               _ = ((X ^ 0) x - (X ^ k) x) + ((X ^ k) x - (X ^ (k + 1)) x)
--                 := by rw [ih]
--               _ = (X ^ 0) x - (X ^ (k + 1)) x
--                 := by abel

--         simp [telescope N]




lemma telescoping_left {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) :
  (ContinuousLinearMap.id â„ E - X).comp (neumannSeriesSum h) =
  ContinuousLinearMap.id â„ E := by
  unfold neumannSeriesSum

  -- The series converges
  have h_summable := operator_series_summable_of_norm_lt_one h

  -- Strategy: Show the norm of the difference goes to zero
  suffices â€–(ContinuousLinearMap.id â„ E - X).comp (âˆ‘' n, X ^ n) - ContinuousLinearMap.id â„ Eâ€– = 0 by
    have : (ContinuousLinearMap.id â„ E - X).comp (âˆ‘' n, X ^ n) - ContinuousLinearMap.id â„ E = 0 :=
      norm_eq_zero.mp this
    exact eq_of_sub_eq_zero this

  -- The partial sums converge in norm
  have h_partial : âˆ€ Îµ > 0, âˆƒ N, âˆ€ n â‰¥ N,
    â€–(âˆ‘ k âˆˆ Finset.range n, X ^ k) - âˆ‘' k, X ^ kâ€– < Îµ := by
    intro Îµ hÎµ
    have := h_summable.hasSum.tendsto_sum_nat
    rw [Metric.tendsto_atTop] at this
    exact this Îµ hÎµ

  -- Apply finite telescoping and X^N â†’ 0
  have h_zero_lim : âˆ€ Îµ > 0, âˆƒ N, âˆ€ n â‰¥ N, â€–X ^ nâ€– < Îµ := by
    intro Îµ hÎµ
    have h_geom : Tendsto (fun n => â€–Xâ€– ^ n) atTop (ğ“ 0) :=
      tendsto_pow_atTop_nhds_zero_of_lt_one (norm_nonneg X) h
    rw [Metric.tendsto_atTop] at h_geom
    obtain âŸ¨N, hNâŸ© := h_geom Îµ hÎµ
    use N
    intro n hn
    calc â€–X ^ nâ€–
        â‰¤ â€–Xâ€– ^ n := norm_pow_le_pow_norm X n
        _ < Îµ := by simpa using hN n hn

  -- Show the composed series equals I
  rw [norm_eq_zero]

  -- For any Îµ > 0, we can make the difference small
  by_contra h_nonzero
  -- Convert negation of equality to positive norm
  have h_pos : 0 < â€–(ContinuousLinearMap.id â„ E - X).comp (âˆ‘' n, X ^ n) - ContinuousLinearMap.id â„ Eâ€– := by
    rwa [norm_pos_iff]

  -- Choose a specific Îµ to work with
  set Îµ := â€–(ContinuousLinearMap.id â„ E - X).comp (âˆ‘' n, X ^ n) - ContinuousLinearMap.id â„ Eâ€– / 3
  have hÎµ_pos : 0 < Îµ := by
    simp only [Îµ]
    apply div_pos h_pos
    norm_num

  -- Choose N large enough for both conditions
  obtain âŸ¨Nâ‚, hNâ‚âŸ© := h_partial (Îµ / max â€–ContinuousLinearMap.id â„ E - Xâ€– 1)
                                  (div_pos hÎµ_pos (lt_max_of_lt_right zero_lt_one))
  obtain âŸ¨Nâ‚‚, hNâ‚‚âŸ© := h_zero_lim Îµ hÎµ_pos

  set N := max Nâ‚ Nâ‚‚

  -- Use N to get a contradiction
  have h_approx := hNâ‚ N (le_max_left _ _)
  have h_small := hNâ‚‚ N (le_max_right _ _)

  -- Estimate using triangle inequality
  have : 3 * Îµ = â€–(ContinuousLinearMap.id â„ E - X).comp (âˆ‘' n, X ^ n) - ContinuousLinearMap.id â„ Eâ€– := by
    simp [Îµ]
    field_simp

  -- Derive the contradiction
  have h_ineq : 3 * Îµ â‰¤ 2 * Îµ := by
    calc 3 * Îµ = â€–(ContinuousLinearMap.id â„ E - X).comp (âˆ‘' n, X ^ n) - ContinuousLinearMap.id â„ Eâ€– := this
        _ â‰¤ â€–(ContinuousLinearMap.id â„ E - X).comp (âˆ‘' n, X ^ n) -
              (ContinuousLinearMap.id â„ E - X).comp (âˆ‘ n âˆˆ Finset.range N, X ^ n)â€– +
            â€–(ContinuousLinearMap.id â„ E - X).comp (âˆ‘ n âˆˆ Finset.range N, X ^ n) -
              ContinuousLinearMap.id â„ Eâ€– := by
          -- Apply triangle inequality â€–x - zâ€– â‰¤ â€–x - yâ€– + â€–y - zâ€–
          have h_tri : âˆ€ (x y z : E â†’L[â„] E), â€–x - zâ€– â‰¤ â€–x - yâ€– + â€–y - zâ€– := by
            intros x y z
            calc â€–x - zâ€– = â€–(x - y) + (y - z)â€– := by abel_nf
                  _ â‰¤ â€–x - yâ€– + â€–y - zâ€– := norm_add_le _ _
          exact h_tri _ _ _
        _ = â€–(ContinuousLinearMap.id â„ E - X).comp ((âˆ‘' n, X ^ n) - âˆ‘ n âˆˆ Finset.range N, X ^ n)â€– +
            â€–ContinuousLinearMap.id â„ E - X ^ N - ContinuousLinearMap.id â„ Eâ€– := by
          rw [â† comp_sub, finite_telescoping N]
        _ â‰¤ â€–ContinuousLinearMap.id â„ E - Xâ€– * â€–(âˆ‘' n, X ^ n) - âˆ‘ n âˆˆ Finset.range N, X ^ nâ€– +
            â€–X ^ Nâ€– := by
          gcongr
          Â· exact ContinuousLinearMap.opNorm_comp_le _ _
          Â· simp [norm_neg]
        _ â‰¤ â€–ContinuousLinearMap.id â„ E - Xâ€– * (Îµ / max â€–ContinuousLinearMap.id â„ E - Xâ€– 1) +
            Îµ := by
          gcongr
          Â· rw [norm_sub_rev]
            exact le_of_lt h_approx
        _ â‰¤ Îµ + Îµ := by
          gcongr
          -- Since â€–ContinuousLinearMap.id â„ E - Xâ€– â‰¤ max â€–ContinuousLinearMap.id â„ E - Xâ€– 1
          -- we have the desired bound directly
          calc â€–ContinuousLinearMap.id â„ E - Xâ€– * (Îµ / max â€–ContinuousLinearMap.id â„ E - Xâ€– 1)
              â‰¤ max â€–ContinuousLinearMap.id â„ E - Xâ€– 1 * (Îµ / max â€–ContinuousLinearMap.id â„ E - Xâ€– 1) := by
                gcongr
                exact le_max_left _ _
            _ = Îµ := by
              field_simp
        _ = 2 * Îµ := by ring

  -- This is impossible since Îµ > 0
  have : 3 * Îµ > 2 * Îµ := by
    linarith [hÎµ_pos]

  -- Contradiction!
  linarith [h_ineq, this]



lemma neumann_comm {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) :
  (ContinuousLinearMap.id â„ E - X).comp (neumannSeriesSum h) =
  (neumannSeriesSum h).comp (ContinuousLinearMap.id â„ E - X) := by
  unfold neumannSeriesSum
  have h_summable := operator_series_summable_of_norm_lt_one h

  -- X^n commutes with (I - X) for each n
  have h_comm_finite : âˆ€ n, (ContinuousLinearMap.id â„ E - X).comp (X ^ n) =
                            (X ^ n).comp (ContinuousLinearMap.id â„ E - X) := by
    intro n
    ext x
    simp only [comp_apply, sub_apply, id_apply]
    -- Need: X^n x - X(X^n x) = X^n x - X^n(X x)
    -- This is true because X(X^n x) = X^{n+1} x = X^n(X x)
    calc (X ^ n) x - X ((X ^ n) x)
        = (X ^ n) x - (X ^ (n + 1)) x := by
          simp [pow_succ']
        _ = (X ^ n) x - (X ^ n) (X x) := by
          rw [pow_succ]
          rfl
    sorry

  -- Apply to infinite sum
  ext x
  simp [comp_apply, sub_apply]
  sorry

  -- exact congr_fun (congr_arg DFunLike.coe (h_comm_finite n)) x



lemma telescoping_right {X : E â†’L[â„] E} (h : â€–Xâ€– < 1) :
  (neumannSeriesSum h).comp (ContinuousLinearMap.id â„ E - X) =
  ContinuousLinearMap.id â„ E := by
  rw [â† neumann_comm h]
  exact telescoping_left h



/--
**Main Neumann Series Theorem (IsUnit version)**

If `â€–I - Bâ€– < 1` for a continuous linear map B on a Banach space, then `B` is a unit (invertible).
We construct the unit explicitly using the Neumann series as the inverse.
-/
theorem isUnit_of_norm_sub_id_lt_one {B : E â†’L[â„] E}
  (h : â€–(ContinuousLinearMap.id â„ E) - Bâ€– < 1) :
  IsUnit B := by
  classical
  -- set `X := id - B`; the inverse will be `S := âˆ‘ X^n`, and `B = id - X`
  set X := (ContinuousLinearMap.id â„ E - B)
  have hX : â€–Xâ€– < 1 := by simpa [X]
  have hB : B = ContinuousLinearMap.id â„ E - X := by
    simp [X]
  -- Candidate inverse:
  let S := neumannSeriesSum hX
  -- Show left/right inverse identities using the telescoping lemmas.
  have hL : (ContinuousLinearMap.id â„ E - X).comp S = ContinuousLinearMap.id â„ E := by
    simpa using telescoping_left (X := X) hX
  have hR : S.comp (ContinuousLinearMap.id â„ E - X) = ContinuousLinearMap.id â„ E := by
    simpa using telescoping_right (X := X) hX
  -- Build a `Units` structure explicitly.
  refine âŸ¨âŸ¨B, S, ?_, ?_âŸ©, rflâŸ©
  Â· -- `B * S = 1` (multiplication is composition)
    -- `hL : (id - X) âˆ˜ S = id`, and `B = id - X`.
    -- Convert composition equality to `*` equality.
    -- `ext` to compare as maps.
    have : (B.comp S) = (ContinuousLinearMap.id â„ E) := by simpa [hB]
      using hL
    -- turn equality of maps into equality of elements in the monoid
    simpa using this
  Â· -- `S * B = 1`
    have : (S.comp B) = (ContinuousLinearMap.id â„ E) := by
      simpa [hB] using hR
    simpa using this

/--
Alternative version with explicit inverse construction
-/
theorem invertible_of_norm_sub_id_lt_one {B : E â†’L[â„] E}
  (h : â€–(1 : E â†’L[â„] E) - Bâ€– < 1) :
  âˆƒ (B_inv : E â†’L[â„] E),
    B * B_inv = 1 âˆ§ B_inv * B = 1 := by
  have hu := isUnit_of_norm_sub_id_lt_one h
  obtain âŸ¨u, rflâŸ© := hu
  exact âŸ¨u.inv, u.val_inv, u.inv_valâŸ©

end NeumannSeries





/-
================================================================================
# NONDEGENERACY AND INVERTIBILITY
================================================================================

Definition 2.3.2 (page 20): "A point xÌƒ âˆˆ U is a nondegenerate zero of f
if f(xÌƒ) = 0 and Df(xÌƒ) is invertible."

We need to establish when Df is invertible. A key lemma is that if
â€–I - ADf(xÌ„)â€– < 1, then ADf(xÌ„) is invertible (used in proof of Theorem 2.4.2).
-/


/--
A point is a nondegenerate zero if it's a zero and the derivative is invertible.
-/
def IsNondegenerateZero (f : E â†’ E) (x : E) : Prop :=
  f x = 0 âˆ§ DifferentiableAt â„ f x âˆ§ IsUnit (fderiv â„ f x)


/-
================================================================================
# CONTRACTION PROPERTY OF THE NEWTON-LIKE MAP
================================================================================

From Section 2.3 (page 20): "If xÌƒ is a nondegenerate zero, then in a small
neighborhood of xÌƒ, T is a contraction mapping with small contraction constant."

The key calculation is DT(xÌƒ) = I - Df(xÌƒ)â»Â¹Df(xÌƒ) = 0 at a zero.
-/

/--
The derivative of the Newton-like map T(x) = x - A(f(x)) is DT(x) = I - Aâˆ˜Df(x).
-/
lemma deriv_newton_like_map {f : E â†’ E} {A : E â†’L[â„] E} {x : E}
  (hf : DifferentiableAt â„ f x) :
  fderiv â„ (NewtonLikeMap f A) x = id - A.comp (fderiv â„ f x) := by
  -- Use the chain rule and linearity of differentiation
  unfold NewtonLikeMap
  -- The derivative of x â†¦ x - A(f(x)) is id - A âˆ˜ Df
  calc fderiv â„ (fun x => x - A (f x)) x
      = fderiv â„ id x - fderiv â„ (A âˆ˜ f) x := by
        -- Derivative of difference is difference of derivatives
        sorry
    _ = id - A.comp (fderiv â„ f x) := by
        -- fderiv of id is id, and chain rule for A âˆ˜ f
        sorry

/-
================================================================================
# MEAN VALUE INEQUALITY APPLICATION
================================================================================

From Corollary 2.2.6 and the proof of Theorem 2.4.1:
We use the mean value inequality to show T maps a ball into itself and is contractive.
-/

/--
A helper lemma that applies the mean value theorem specifically for our Newton map.
This bridges between the abstract derivative bounds and concrete distance estimates.
-/
lemma newton_map_lipschitz_on_ball
  {f : E â†’ E} {A : E â†’L[â„] E} {xBar : E} {r Z_r : â„}
  (hf_diff : DifferentiableOn â„ (NewtonLikeMap f A) (closedBall xBar r))
  (hZ : âˆ€ x âˆˆ closedBall xBar r, â€–fderiv â„ (NewtonLikeMap f A) xâ€– â‰¤ Z_r) :
  âˆ€ x y âˆˆ closedBall xBar r,
    â€–NewtonLikeMap f A x - NewtonLikeMap f A yâ€– â‰¤ Z_r * â€–x - yâ€– := by
  intros x hx y hy
  -- The closed ball is convex
  haveI h_convex : Convex â„ (closedBall xBar r) := convex_closedBall xBar r
  -- Apply the mean value theorem on the convex set
  apply h_convex.norm_image_sub_le_of_norm_fderivWithin_le
  Â· exact hf_diff
  Â· intro z hz
    -- Convert fderivWithin to fderiv since we're on an open neighborhood
    rw [DifferentiableOn.fderivWithin_eq_fderiv (hf_diff)
        (isOpen_ball.mem_nhds _)] at hZ
    Â· exact hZ z hz
    Â· sorry -- Need to show z is in the interior for this conversion
  Â· exact hx
  Â· exact hy

/--
If T satisfies certain bounds, then it maps a closed ball into itself.
This is the key step in proving T has a fixed point via contraction mapping theorem.

The proof follows the structure from Theorem 2.4.1 (page 21) of the informal proof:
1. Start with â€–T(x) - xÌ„â€– and split using triangle inequality
2. Apply mean value inequality to bound â€–T(x) - T(xÌ„)â€–
3. Use the bounds Y0 and Z_r to show the result is < r
-/
lemma newton_map_preserves_ball
  {f : E â†’ E} {A : E â†’L[â„] E} {xBar : E} {r Y0 Z_r : â„}
  (hf_diff : DifferentiableOn â„ (NewtonLikeMap f A) (closedBall xBar r))
  (hr : 0 < r)
  (hY0 : â€–NewtonLikeMap f A xBar - xBarâ€– â‰¤ Y0)
  (hZ : âˆ€ x âˆˆ closedBall xBar r, â€–fderiv â„ (NewtonLikeMap f A) xâ€– â‰¤ Z_r)
  (hp : Z_r * r + Y0 < r) :
  MapsTo (NewtonLikeMap f A) (closedBall xBar r) (closedBall xBar r) := by
  -- Unpack what we need to prove: for any x in the ball, T(x) is also in the ball
  intro x hx
  rw [mem_closedBall] at hx âŠ¢

  -- Step 1: Apply triangle inequality to split â€–T(x) - xÌ„â€–
  -- This is equation (2.19) in the informal proof
  calc â€–NewtonLikeMap f A x - xBarâ€–
      â‰¤ â€–NewtonLikeMap f A x - NewtonLikeMap f A xBarâ€– +
        â€–NewtonLikeMap f A xBar - xBarâ€– :=
          norm_sub_le _ _  -- Triangle inequality
    _ â‰¤ Z_r * â€–x - xBarâ€– + Y0 := by
        apply add_le_add
        Â· -- First term: Apply our Lipschitz lemma
          exact newton_map_lipschitz_on_ball hf_diff hZ x hx xBar
            (mem_closedBall_self (le_of_lt hr))
        Â· -- Second term: Direct from hypothesis hY0
          exact hY0
    _ â‰¤ Z_r * r + Y0 := by
        -- Since x âˆˆ closedBall xBar r, we have â€–x - xBarâ€– â‰¤ r
        gcongr
        exact hx
    _ < r := hp  -- This is our hypothesis that p(r) < 0 implies this inequality

/-
================================================================================
# RADII POLYNOMIAL SETUP
================================================================================

From Theorem 2.4.2 (page 22): The radii polynomial approach with bounds Y0, Z0, Z2.
-/

/--
Radii polynomial data structure with the three key bounds.
Y0 bounds â€–Af(xÌ„)â€–, Z0 bounds â€–I - ADf(xÌ„)â€–, Z2 bounds the derivative variation.
-/
structure RadiiPolynomialData : Type where
  Y0 : â„  -- Bound on â€–Af(xÌ„)â€–
  Z0 : â„  -- Bound on â€–I - ADf(xÌ„)â€–
  Z2 : â„ â†’ â„  -- Bound on â€–A[Df(c) - Df(xÌ„)]â€–/r for c âˆˆ B_r(xÌ„)
  Y0_nonneg : 0 â‰¤ Y0
  Z0_nonneg : 0 â‰¤ Z0
  Z2_nonneg : âˆ€ {r}, 0 < r â†’ 0 â‰¤ Z2 r

namespace RadiiPolynomialData

/--
The combined bound Z(r) = Zâ‚€ + Zâ‚‚(r)Â·r from equation (2.18).
-/
def Z_combined (data : RadiiPolynomialData) (r : â„) : â„ :=
  data.Z0 + (data.Z2 r) * r

/--
The radii polynomial p(r) = Zâ‚‚(r)rÂ² - (1 - Zâ‚€)r + Yâ‚€ from equation (2.17).
-/
def radiusPolynomial (data : RadiiPolynomialData) (r : â„) : â„ :=
  (data.Z2 r) * r^2 - (1 - data.Z0) * r + data.Y0

/--
Alternative formulation: p(r) = (Z(r) - 1)r + Yâ‚€.
This shows the connection to the contraction condition Z(r) < 1.
-/
lemma radiusPolynomial_rw (data : RadiiPolynomialData) (r : â„) :
  data.radiusPolynomial r = (data.Z_combined r - 1) * r + data.Y0 := by
  unfold radiusPolynomial Z_combined
  ring

/--
If p(r) < 0, then Z(r) < 1 (contraction) and the ball is mapped into itself.
-/
lemma radiusPolynomial_negative_implies_contraction
  {data : RadiiPolynomialData} {r : â„}
  (hr : 0 < r) (hp : data.radiusPolynomial r < 0) :
  data.Z_combined r < 1 âˆ§ data.Z_combined r * r + data.Y0 < r := by
  rw [radiusPolynomial_rw] at hp
  constructor
  Â· -- Prove Z(r) < 1
    haveI : (data.Z_combined r - 1) * r + data.Y0 < 0 := hp
    haveI : 0 â‰¤ data.Y0 := data.Y0_nonneg
    -- Since Y0 â‰¥ 0 and the sum is < 0, we need (Z(r) - 1) * r < 0
    haveI : (data.Z_combined r - 1) * r < 0 := by linarith
    -- Since r > 0, we need Z(r) - 1 < 0, hence Z(r) < 1
    haveI : data.Z_combined r - 1 < 0 := by
      -- Assume `Z(r) - 1 â‰¥ 0`
      by_contra h_not
      haveI : 0 â‰¤ data.Z_combined r - 1 := by linarith
      -- Then `(Z(r) - 1) * r â‰¥ 0` since `r > 0`.
      -- `this` is the immediate conclusion 0 â‰¤ data.Z_combined r - 1
      -- hr.le is `r â‰¤ 0` relaxed from `0 < r`
      haveI : 0 â‰¤ (data.Z_combined r - 1) * r := mul_nonneg this hr.le
      linarith
    linarith

  Â· -- Prove Z(r) * r + Y0 < r
    calc data.Z_combined r * r + data.Y0
        = (data.Z_combined r - 1) * r + r + data.Y0 := by ring
      _ = ((data.Z_combined r - 1) * r + data.Y0) + r := by ring
      _ < 0 + r := by linarith [hp]
      _ = r := by ring

end RadiiPolynomialData

/-
================================================================================
# MAIN RADII POLYNOMIAL THEOREM (Theorem 2.4.2)
================================================================================

This is the main result that guarantees existence of a unique nondegenerate zero.
-/

/--
Main radii polynomial theorem for proving existence of nondegenerate zeros.
If the radii polynomial has a negative value at some râ‚€ > 0, then there exists
a unique zero xÌƒ in the ball B_râ‚€(xÌ„), and this zero is nondegenerate.
-/
theorem radii_polynomial_theorem
  {f : E â†’ E} {xBar : E} {A : E â†’L[â„] E}
  (hf_diff : âˆ€ x, DifferentiableAt â„ f x)
  (data : RadiiPolynomialData)
  -- The three key bounds from equations (2.14), (2.15), (2.16)
  (hY0 : â€–A (f xBar)â€– â‰¤ data.Y0)
  (hZ0 : â€–id - A.comp (fderiv â„ f xBar)â€– â‰¤ data.Z0)
  (hZ2 : âˆ€ (c : E) (r : â„), c âˆˆ closedBall xBar r â†’ 0 < r â†’
         â€–A.comp ((fderiv â„ f c) - (fderiv â„ f xBar))â€– â‰¤ data.Z2 r * r)
  -- If the polynomial is negative at some râ‚€
  {r0 : â„} (hr0_pos : 0 < r0)
  (hp_neg : data.radiusPolynomial r0 < 0) :
  -- Then there exists a unique nondegenerate zero in the ball
  âˆƒ! (x_tilde : E), x_tilde âˆˆ closedBall xBar r0 âˆ§
                     IsNondegenerateZero f x_tilde := by
  -- Step 1: Show that T = NewtonLikeMap f A is a contraction on closedBall xBar r0

  -- From p(râ‚€) < 0, we get Z(râ‚€) < 1 and the self-mapping property
  obtain âŸ¨hZ_lt_one, hself_mapâŸ© :=
    data.radiusPolynomial_negative_implies_contraction hr0_pos hp_neg

  -- Step 2: Apply the Contraction Mapping Theorem
  -- We need to show:
  -- (a) T maps the ball into itself
  -- (b) T is a contraction with constant < 1
  -- (c) The ball is complete (follows from E being complete)

  sorry -- This requires assembling all the pieces with the contraction mapping theorem

/-
================================================================================
# CONVERGENCE TO NEWTON'S METHOD
================================================================================

From Section 2.5 (mentioned in the user's request):
If xÌƒ is a zero, Df(xÌƒ) is invertible, xÌ„ is sufficiently close to xÌƒ,
and we have sufficient computational resources, then the radii polynomial
approach guarantees finding xÌƒ.
-/

/--
If the initial guess is sufficiently close to a nondegenerate zero,
then the radii polynomial approach succeeds.
-/
theorem radii_success_near_nondegenerate_zero
  {f : E â†’ E} {x_tilde xBar : E} {A : E â†’L[â„] E}
  (hf_diff : âˆ€ x, DifferentiableAt â„ f x)
  (h_zero : IsNondegenerateZero f x_tilde)
  (hA_approx : â€–A - (fderiv â„ f x_tilde).inverseâ€– < Îµ)
  (h_close : â€–xBar - x_tildeâ€– < Î´)
  -- For sufficiently small Îµ and Î´
  (hÎµ : Îµ > 0) (hÎ´ : Î´ > 0) (h_small : Îµ * Î´ < 1/4) :
  -- Then there exists r > 0 such that the radii polynomial is negative
  âˆƒ (r : â„) (data : RadiiPolynomialData),
    0 < r âˆ§
    data.radiusPolynomial r < 0 âˆ§
    x_tilde âˆˆ closedBall xBar r := by
  -- The proof follows from continuity arguments and the fact that
  -- at a nondegenerate zero, DT(xÌƒ) = 0, making T a strong contraction nearby
  sorry
